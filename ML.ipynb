{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "\n",
    "# Skimage & Mahotas for feature extraction\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import regionprops\n",
    "import mahotas as mt\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, make_scorer\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Add XGBoost as suggested in research plan\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay"
   ],
   "id": "1ddf5098931477fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CONFIGURATION",
   "id": "a9d2fbc91682d1c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Global Configuration\n",
    "ROOT_OUTPUT_DIR = \"D:\\iate_project\\ml_output\"\n",
    "FEATURE_EXTRACTION_DIR = os.path.join(ROOT_OUTPUT_DIR, 'ml_features', 'ml_feature_extraction')\n",
    "RESULTS_DIR = os.path.join(ROOT_OUTPUT_DIR, 'ml_classification_results')\n",
    "MODELS_DIR = os.path.join(RESULTS_DIR, 'ml_models')\n",
    "PLOTS_DIR = os.path.join(RESULTS_DIR, 'ml_plots')"
   ],
   "id": "94995fb242449d4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create necessary directories\n",
    "for d in [ROOT_OUTPUT_DIR, FEATURE_EXTRACTION_DIR, RESULTS_DIR, MODELS_DIR, PLOTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ],
   "id": "7ea425b8db36ff33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Custom logging handler to filter progress bars from console output\n",
    "class FilteredStreamHandler(logging.StreamHandler):\n",
    "    def emit(self, record):\n",
    "        if record.levelno >= logging.INFO:  # Only show INFO and above in console\n",
    "            super().emit(record)"
   ],
   "id": "5cab9f1100ad99ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set up logging - Drastically reduced console output\n",
    "LOG_PATH = os.path.join(RESULTS_DIR, 'classification_and_feature_extraction.log')\n",
    "file_handler = logging.FileHandler(LOG_PATH)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "console_handler = FilteredStreamHandler()\n",
    "console_handler.setFormatter(logging.Formatter('>>> %(message)s'))\n",
    "\n",
    "logger = logging.getLogger('coffee_bean_classification')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "logger.propagate = False"
   ],
   "id": "c03ac1e841c4b023"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define classifiers with optimized hyperparameters based on research\n",
    "CLASSIFIERS = {\n",
    "    'SVM': {\n",
    "        'model': SVC(\n",
    "            C=150,\n",
    "            kernel='rbf',\n",
    "            probability=True,\n",
    "            random_state=42,\n",
    "            cache_size=1000\n",
    "        ),\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=20,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=4,\n",
    "            max_features='log2',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=20,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective='binary:logistic',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'model': ExtraTreesClassifier(\n",
    "            n_estimators=600,\n",
    "            max_depth=50,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=4,\n",
    "            max_features='log2',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'expects_proba': True\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(\n",
    "            n_neighbors=9,\n",
    "            weights='distance',\n",
    "            algorithm='auto',\n",
    "            metric='euclidean',\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(\n",
    "            max_depth=50,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=4,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'expects_proba': True\n",
    "    }\n",
    "}"
   ],
   "id": "f4020d85185c68e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define feature categories as mentioned in research plan\n",
    "FEATURE_CATEGORIES = {\n",
    "    'color': ['correlogram_'],  # Color features using correlogram\n",
    "    'texture': ['glcm_'],       # Texture features using GLCM\n",
    "    'shape': ['area', 'perimeter', 'eccentricity', 'extent', 'solidity']  # Shape features\n",
    "}"
   ],
   "id": "fdb6426775cd4c6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# INITIALIZATION",
   "id": "bd199b01b5b76e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"     COFFEE BEAN CLASSIFICATION WITH TRADITIONAL MACHINE LEARNING\")\n",
    "print(\"=\"*70)\n",
    "logger.info(\"Starting coffee bean classification pipeline\")"
   ],
   "id": "d3c334dd3e907ecd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Record resource usage at the beginning\n",
    "process = psutil.Process(os.getpid())\n",
    "cpu_usage_before = psutil.cpu_percent(interval=None)\n",
    "mem_info_before = process.memory_info()\n",
    "memory_usage_mb_before = mem_info_before.rss / 1024 / 1024\n",
    "\n",
    "start_time_script = time.time()"
   ],
   "id": "99f1bbcd4fad73ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature Extraction Configuration\n",
    "do_feature_extraction = True"
   ],
   "id": "b926b89b6222b136"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define path structure based on dataset description\n",
    "original_dataset_path = \"D:\\iate_project\\original_dataset\"\n",
    "output_dir = FEATURE_EXTRACTION_DIR\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "id": "91b2885ce97a87ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FEATURE EXTRACTION",
   "id": "3637a089924b8c9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = None\n",
    "\n",
    "if do_feature_extraction:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"     STAGE 1: FEATURE EXTRACTION\")\n",
    "    print(\"-\"*70)\n",
    "    logger.info(\"Feature Extraction started\")\n",
    "\n",
    "    # Timers for each method\n",
    "    method_times = {\n",
    "        'color_correlogram': 0.0,\n",
    "        'glcm': 0.0,\n",
    "        'region_props': 0.0\n",
    "    }\n",
    "\n",
    "    # Lists to hold extracted data\n",
    "    feats_list = []\n",
    "    labels_ = []\n",
    "    paths_ = []\n",
    "    splits_ = []\n",
    "\n",
    "    t_start_fe = time.time()\n",
    "\n",
    "    # Create storage for class distribution info\n",
    "    class_counts = {'train': {'Normal': 0, 'Defect': 0},\n",
    "                    'test': {'Normal': 0, 'Defect': 0}}\n",
    "\n",
    "    # Process image directories based on the specified structure\n",
    "    classes = ['normal', 'defect']\n",
    "    processing_types = ['dry', 'honey', 'wet']\n",
    "    roast_levels = ['dark', 'light', 'medium']\n",
    "\n",
    "    # Define train/test split ratio (70% train, 30% test)\n",
    "    train_ratio = 0.7\n",
    "\n",
    "    # Count total files for progress tracking\n",
    "    total_files_count = 0\n",
    "    for class_name in classes:\n",
    "        for proc_type in processing_types:\n",
    "            for roast in roast_levels:\n",
    "                subfolder_path = os.path.join(original_dataset_path, class_name, proc_type, roast)\n",
    "                if os.path.exists(subfolder_path):\n",
    "                    image_files = [f for f in os.listdir(subfolder_path)\n",
    "                                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                    total_files_count += len(image_files)\n",
    "\n",
    "    print(f\"Total images to process: {total_files_count}\")\n",
    "    print(\"Starting feature extraction (this may take some time)...\")\n",
    "\n",
    "    # Track processing times and counts for occasional updates\n",
    "    last_update_time = time.time()\n",
    "    processed_since_update = 0\n",
    "    total_processed = 0\n",
    "\n",
    "    # Walk through the directory structure and extract features\n",
    "    for class_name in classes:\n",
    "        for proc_type in processing_types:\n",
    "            for roast in roast_levels:\n",
    "                # Construct the path to the current subfolder\n",
    "                subfolder_path = os.path.join(original_dataset_path, class_name, proc_type, roast)\n",
    "\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    continue\n",
    "\n",
    "                # Get list of image files in the current subfolder\n",
    "                image_files = [f for f in os.listdir(subfolder_path)\n",
    "                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "                if not image_files:\n",
    "                    continue\n",
    "\n",
    "                # Shuffle files for random split\n",
    "                np.random.seed(42)  # For reproducibility\n",
    "                np.random.shuffle(image_files)\n",
    "\n",
    "                # Split into train and test\n",
    "                split_idx = int(len(image_files) * train_ratio)\n",
    "                train_files = image_files[:split_idx]\n",
    "                test_files = image_files[split_idx:]\n",
    "\n",
    "                # Update class distribution counts\n",
    "                class_counts['train'][class_name] += len(train_files)\n",
    "                class_counts['test'][class_name] += len(test_files)\n",
    "\n",
    "                # Process each split\n",
    "                for split_name, files in [('train', train_files), ('test', test_files)]:\n",
    "                    batch_start = time.time()\n",
    "                    batch_size = len(files)\n",
    "\n",
    "                    # Log batch info - for log file only\n",
    "                    logger.info(f\"Processing {batch_size} images from {class_name}/{proc_type}/{roast}/{split_name}\")\n",
    "\n",
    "                    # Show batch progress in console\n",
    "                    print(f\"Processing {batch_size} images from {class_name}/{proc_type}/{roast}/{split_name}\")\n",
    "\n",
    "                    for file_ in files:\n",
    "                        # Construct full path to the image\n",
    "                        img_path = os.path.join(subfolder_path, file_)\n",
    "\n",
    "                        # Read and process the image\n",
    "                        try:\n",
    "                            # Read color image\n",
    "                            color_img_ = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "                            if color_img_ is None:\n",
    "                                total_processed += 1\n",
    "                                processed_since_update += 1\n",
    "                                continue\n",
    "\n",
    "                            # Convert BGR to RGB\n",
    "                            color_img_ = cv2.cvtColor(color_img_, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                            # Create grayscale image\n",
    "                            gray_img_ = cv2.cvtColor(color_img_, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "                            # Create threshold image (Otsu's method)\n",
    "                            _, thresh_img_ = cv2.threshold(gray_img_, 0, 255,\n",
    "                                                        cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "                            # Extract features\n",
    "                            # 1. Color correlogram - as referenced in research plan\n",
    "                            t0_ = time.time()\n",
    "                            correlogram = []\n",
    "                            for d in [1, 2, 3]:  # Distances\n",
    "                                for i in range(3):  # RGB channels\n",
    "                                    channel = color_img_[:, :, i]\n",
    "                                    haralick = mt.features.haralick(channel, distance=d)\n",
    "                                    correlogram.extend(haralick.mean(axis=0).tolist())\n",
    "                            cost_c = time.time() - t0_\n",
    "                            method_times['color_correlogram'] += cost_c\n",
    "\n",
    "                            # 2. GLCM features - as referenced in research plan\n",
    "                            t1_ = time.time()\n",
    "                            glcm_ = graycomatrix(\n",
    "                                gray_img_,\n",
    "                                distances=[1, 2, 3],\n",
    "                                angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                symmetric=True,\n",
    "                                normed=True\n",
    "                            )\n",
    "                            glcm_features = []\n",
    "                            props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "                            for prop in props:\n",
    "                                val_ = graycoprops(glcm_, prop)\n",
    "                                glcm_features.extend(val_.flatten().tolist())\n",
    "                            cost_g = time.time() - t1_\n",
    "                            method_times['glcm'] += cost_g\n",
    "\n",
    "                            # 3. Region properties - shape features from research plan\n",
    "                            t2_ = time.time()\n",
    "                            regions = regionprops(thresh_img_.astype(np.uint8))\n",
    "                            if not regions:\n",
    "                                region_features = [0] * 5\n",
    "                            else:\n",
    "                                props_ = regions[0]\n",
    "                                region_features = [\n",
    "                                    props_.area,\n",
    "                                    props_.perimeter,\n",
    "                                    props_.eccentricity,\n",
    "                                    props_.extent,\n",
    "                                    props_.solidity\n",
    "                                ]\n",
    "                            cost_r = time.time() - t2_\n",
    "                            method_times['region_props'] += cost_r\n",
    "\n",
    "                            # Combine all features\n",
    "                            flatten_vec = correlogram + glcm_features + region_features\n",
    "                            feats_list.append(flatten_vec)\n",
    "                            labels_.append(class_name)\n",
    "                            paths_.append(os.path.join(class_name, proc_type, roast, file_))\n",
    "                            splits_.append(split_name)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error processing {img_path}: {str(e)}\")\n",
    "\n",
    "                        # Update progress tracking\n",
    "                        total_processed += 1\n",
    "                        processed_since_update += 1\n",
    "\n",
    "                        # Provide occasional progress updates\n",
    "                        current_time = time.time()\n",
    "                        if current_time - last_update_time > 60:  # Update every minute\n",
    "                            percent_done = (total_processed / total_files_count) * 100\n",
    "                            elapsed = current_time - t_start_fe\n",
    "                            rate = processed_since_update / (current_time - last_update_time)\n",
    "                            remaining = (total_files_count - total_processed) / rate if rate > 0 else 0\n",
    "\n",
    "                            print(f\"Progress: {total_processed}/{total_files_count} images ({percent_done:.1f}%), \"\n",
    "                                  f\"Rate: {rate:.1f} img/sec, Est. remaining: {remaining/60:.1f} min\")\n",
    "\n",
    "                            last_update_time = current_time\n",
    "                            processed_since_update = 0\n",
    "\n",
    "                    # Batch completion summary\n",
    "                    batch_time = time.time() - batch_start\n",
    "                    print(f\"Completed batch in {batch_time:.1f} seconds ({batch_size/batch_time:.1f} img/sec)\")\n",
    "\n",
    "    print(\"Feature extraction completed\")\n",
    "\n",
    "    # Check if we got any data\n",
    "    if not feats_list:\n",
    "        logger.error(\"No features extracted from any images.\")\n",
    "        print(\"ERROR: No features were extracted. Check the logs for details.\")\n",
    "        import sys\n",
    "        sys.exit(-1)\n",
    "\n",
    "    # Generate feature column names\n",
    "    feat_names = (\n",
    "        [f'correlogram_{i}' for i in range(13*3*3)] +  # 117\n",
    "        [f'glcm_{j}' for j in range(5*3*4)] +         # 60\n",
    "        ['area', 'perimeter', 'eccentricity', 'extent', 'solidity']  # 5\n",
    "    )\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(feats_list, columns=feat_names)\n",
    "    df['label'] = labels_\n",
    "    df['image_path'] = paths_\n",
    "    df['split'] = splits_\n",
    "\n",
    "    # Split and scale\n",
    "    print(\"Scaling features...\")\n",
    "    train_df = df[df['split'] == 'train']\n",
    "    test_df = df[df['split'] == 'test']\n",
    "    scaler = StandardScaler()\n",
    "    train_mat = scaler.fit_transform(train_df[feat_names])\n",
    "    test_mat = scaler.transform(test_df[feat_names])\n",
    "    df.loc[df['split'] == 'train', feat_names] = train_mat\n",
    "    df.loc[df['split'] == 'test', feat_names] = test_mat\n",
    "\n",
    "    # Save scaler info\n",
    "    sc_info = {\n",
    "        'mean': scaler.mean_.tolist(),\n",
    "        'scale': scaler.scale_.tolist(),\n",
    "        'feature_names': feat_names\n",
    "    }\n",
    "    with open(os.path.join(output_dir, 'scaler_params.json'), 'w') as f_:\n",
    "        json.dump(sc_info, f_, indent=4)\n",
    "\n",
    "    # Summaries\n",
    "    n_images_ = len(df)\n",
    "    total_spent_ = time.time() - t_start_fe\n",
    "    avg_times_ = {k: (method_times[k]/n_images_) for k in method_times}\n",
    "    method_times['total_time'] = total_spent_\n",
    "    method_times['average_times'] = avg_times_\n",
    "\n",
    "    # Save CSV of extracted features\n",
    "    output_csv_path = os.path.join(output_dir, 'coffee_bean_features.csv')\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    # Build metadata\n",
    "    class_dist = df.groupby(['split', 'label']).size()\n",
    "    class_dist_dict = {\n",
    "        f\"{sp}_{lb}\": cnt\n",
    "        for (sp, lb), cnt in class_dist.items()\n",
    "    }\n",
    "    feature_dims = {\n",
    "        'color_correlogram': 13*3*3,  # 117\n",
    "        'glcm': 5*3*4,               # 60\n",
    "        'region_props': 5\n",
    "    }\n",
    "    meta_ = {\n",
    "        'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'processing_time': {\n",
    "            'total_time': f\"{method_times['total_time']:.2f} seconds\",\n",
    "            'method_breakdown': {\n",
    "                k: f\"{method_times[k]:.2f} seconds\"\n",
    "                for k in method_times\n",
    "                if k not in ['total_time', 'average_times']\n",
    "            },\n",
    "            'average_times': {\n",
    "                k: f\"{avg_times_[k]:.4f} seconds/image\"\n",
    "                for k in avg_times_\n",
    "                if k not in ['total_time', 'average_times']\n",
    "            }\n",
    "        },\n",
    "        'dataset_statistics': {\n",
    "            'total_samples': len(df),\n",
    "            'class_distribution': class_dist_dict,\n",
    "            'feature_dimensions': feature_dims,\n",
    "            'total_dimensions': sum(feature_dims.values())\n",
    "        },\n",
    "        'parameters': {\n",
    "            'color_correlogram_distances': [1, 2, 3],\n",
    "            'glcm_distances': [1, 2, 3],\n",
    "            'glcm_angles': [0, 45, 90, 135]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    meta_path_ = os.path.join(output_dir, 'extraction_metadata.json')\n",
    "    with open(meta_path_, 'w') as f_:\n",
    "        json.dump(meta_, f_, indent=4)\n",
    "\n",
    "    # Print extraction summary\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"                  FEATURE EXTRACTION SUMMARY\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"Total samples: {len(df)} images\")\n",
    "    print(f\"Feature dimensionality: {meta_['dataset_statistics']['total_dimensions']} features\")\n",
    "    print(f\"  - Color features (correlogram): {feature_dims['color_correlogram']} dimensions\")\n",
    "    print(f\"  - Texture features (GLCM): {feature_dims['glcm']} dimensions\")\n",
    "    print(f\"  - Shape features: {feature_dims['region_props']} dimensions\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "\n",
    "    for s_ in ['train', 'test']:\n",
    "        dist_s_ = df[df['split'] == s_]['label'].value_counts()\n",
    "        print(f\"  {s_:<5} set => Normal: {dist_s_.get('Normal', 0):<5}, Defect: {dist_s_.get('Defect', 0):<5}\")\n",
    "\n",
    "    print(f\"\\nTotal processing time: {method_times['total_time']:.1f} seconds ({n_images_/method_times['total_time']:.1f} images/sec)\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping feature extraction. Loading features from CSV...\")\n",
    "    csv_path = os.path.join(FEATURE_EXTRACTION_DIR, \"coffee_bean_features.csv\")\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logger.info(f\"Loaded features from {csv_path}\")\n",
    "        print(f\"Loaded {len(df)} samples from {csv_path}\")\n",
    "    else:\n",
    "        logger.error(f\"No feature CSV found at {csv_path}. Cannot proceed.\")\n",
    "        print(f\"ERROR: No feature CSV found at {csv_path}. Cannot proceed.\")\n",
    "        import sys\n",
    "        sys.exit(-1)\n",
    "\n",
    "if df is None:\n",
    "    logger.error(\"No DataFrame available for classification. Aborting.\")\n",
    "    print(\"ERROR: No data available for classification. Aborting.\")\n",
    "    import sys\n",
    "    sys.exit(-1)"
   ],
   "id": "d22b70b55d41e8d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CLASSIFICATION",
   "id": "a61cb8f7af7a0884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"     STAGE 2: CLASSIFICATION AND MODEL EVALUATION\")\n",
    "print(\"-\"*70)\n",
    "logger.info(\"Classification stage started\")"
   ],
   "id": "13eb4834e5f55957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "feat_cols = [c for c in df.columns if c not in ['label', 'image_path', 'split']]\n",
    "train_df_ = df[df['split'] == 'train']\n",
    "test_df_ = df[df['split'] == 'test']\n",
    "\n",
    "X_train = train_df_[feat_cols].values\n",
    "X_test = test_df_[feat_cols].values\n",
    "label_map = {'Normal': 0, 'Defect': 1}\n",
    "y_train = np.array([label_map[l] for l in train_df_['label']])\n",
    "y_test = np.array([label_map[l] for l in test_df_['label']])\n",
    "\n",
    "print(f\"Dataset prepared for classification:\")\n",
    "print(f\"  - Train set: {len(X_train)} samples\")\n",
    "print(f\"  - Test set: {len(X_test)} samples\")\n",
    "print(f\"  - Features: {len(feat_cols)} dimensions\")"
   ],
   "id": "675322786c658669"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define feature combinations to evaluate\n",
    "feature_combos = [\n",
    "    ['color'],\n",
    "    ['texture'],\n",
    "    ['shape'],\n",
    "    ['color', 'texture'],\n",
    "    ['color', 'shape'],\n",
    "    ['texture', 'shape'],\n",
    "    ['color', 'texture', 'shape']\n",
    "]\n",
    "\n",
    "# Setup for results collection\n",
    "all_results = {}\n",
    "best_model_script = {\n",
    "    'score': -1,\n",
    "    'combo': None,\n",
    "    'clf_name': None,\n",
    "    'model': None,\n",
    "    'results': None,\n",
    "    'features': None\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluating feature combinations and classifiers...\")\n",
    "print(\"This will test 7 feature combinations × 7 classifiers = 49 models\")"
   ],
   "id": "1ed540530d643e98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set up evaluation progress tracking\n",
    "total_evals = len(feature_combos) * len(CLASSIFIERS)\n",
    "start_eval_time = time.time()\n",
    "completed_evals = 0"
   ],
   "id": "d71aeafb7f3e4735"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loop through each feature combination\n",
    "for combo_ in feature_combos:\n",
    "    # Select features for this combination\n",
    "    idx_sel_ = []\n",
    "    dims_ = {}\n",
    "\n",
    "    # Select feature indices for current combination\n",
    "    for cat_ in combo_:\n",
    "        cat_cols_ = []\n",
    "        for prefix_ in FEATURE_CATEGORIES[cat_]:\n",
    "            if prefix_.endswith('_'):\n",
    "                found_ = [i for i, c in enumerate(feat_cols) if c.startswith(prefix_)]\n",
    "            else:\n",
    "                found_ = [i for i, c in enumerate(feat_cols) if c == prefix_]\n",
    "            cat_cols_.extend(found_)\n",
    "        dims_[cat_] = len(cat_cols_)\n",
    "        idx_sel_.extend(cat_cols_)\n",
    "\n",
    "    # Extract selected features\n",
    "    X_train_sel_ = X_train[:, idx_sel_]\n",
    "    X_test_sel_ = X_test[:, idx_sel_]\n",
    "    sel_names_ = [feat_cols[i] for i in idx_sel_]\n",
    "\n",
    "    combo_name_ = '+'.join(combo_)\n",
    "    all_results[combo_name_] = {}\n",
    "\n",
    "    # Compact feature info log\n",
    "    feature_info = \", \".join([f\"{c}: {dims_[c]}\" for c in combo_])\n",
    "    print(f\"\\nEvaluating feature combination: '{combo_name_}' ({feature_info})\")\n",
    "\n",
    "    # Evaluate each classifier with this feature combination\n",
    "    for clf_name_, clf_info_ in CLASSIFIERS.items():\n",
    "        eval_start = time.time()\n",
    "\n",
    "        # Create a pipeline with just the classifier\n",
    "        pipeline_ = Pipeline([\n",
    "            ('classifier', clf_info_['model'])\n",
    "        ])\n",
    "\n",
    "        # Cross-validation - Changed from 5-fold to 10-fold\n",
    "        cv_metrics_ = {}\n",
    "        splitter_ = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        scoring_ = {\n",
    "            'accuracy': 'accuracy',\n",
    "            'precision': make_scorer(precision_score, zero_division=0),\n",
    "            'recall': 'recall',\n",
    "            'f1': 'f1',\n",
    "            'roc_auc': 'roc_auc'\n",
    "        }\n",
    "        cv_results_ = cross_validate(\n",
    "            pipeline_, X_train_sel_, y_train,\n",
    "            scoring=scoring_, cv=splitter_, n_jobs=-1, return_train_score=True\n",
    "        )\n",
    "\n",
    "        # Process CV results\n",
    "        for metric, scores in [(k.replace('test_', ''), cv_results_[k])\n",
    "                               for k in cv_results_ if k.startswith('test_')]:\n",
    "            cv_metrics_[metric] = {\n",
    "                'mean': float(scores.mean()),\n",
    "                'std': float(scores.std()),\n",
    "                'values': scores.tolist()\n",
    "            }\n",
    "\n",
    "        # Final fit on entire train set\n",
    "        pipeline_.fit(X_train_sel_, y_train)\n",
    "\n",
    "        # Predict test set\n",
    "        y_pred_ = pipeline_.predict(X_test_sel_)\n",
    "        y_proba_ = None\n",
    "        if clf_info_['expects_proba']:\n",
    "            y_proba_ = pipeline_.predict_proba(X_test_sel_)[:, 1]\n",
    "\n",
    "        # Compute test metrics\n",
    "        metrics_ = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred_),\n",
    "            'precision': precision_score(y_test, y_pred_),\n",
    "            'recall': recall_score(y_test, y_pred_),\n",
    "            'f1': f1_score(y_test, y_pred_),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba_) if y_proba_ is not None else None\n",
    "        }\n",
    "\n",
    "        # Get feature importances if available\n",
    "        final_clf_ = pipeline_.named_steps['classifier']\n",
    "        feat_imp_ = None\n",
    "        if hasattr(final_clf_, 'feature_importances_'):\n",
    "            feat_imp_ = final_clf_.feature_importances_\n",
    "        elif hasattr(final_clf_, 'coef_'):\n",
    "            feat_imp_ = np.abs(final_clf_.coef_[0])\n",
    "\n",
    "        # Record total time\n",
    "        total_t_ = time.time() - eval_start\n",
    "\n",
    "        # Store results\n",
    "        result_dict_ = {\n",
    "            'model_name': clf_name_,\n",
    "            'cross_validation': cv_metrics_,\n",
    "            'test_performance': metrics_,\n",
    "            'timing': {\n",
    "                'total_time': total_t_\n",
    "            },\n",
    "            'feature_importance': feat_imp_.tolist() if feat_imp_ is not None else None\n",
    "        }\n",
    "        all_results[combo_name_][clf_name_] = result_dict_\n",
    "\n",
    "        # Track the best model by F1 score\n",
    "        cur_f1_ = metrics_['f1']\n",
    "        if cur_f1_ > best_model_script['score']:\n",
    "            best_model_script['score'] = cur_f1_\n",
    "            best_model_script['combo'] = combo_\n",
    "            best_model_script['clf_name'] = clf_name_\n",
    "            best_model_script['model'] = pipeline_\n",
    "            best_model_script['results'] = result_dict_\n",
    "            best_model_script['features'] = sel_names_\n",
    "\n",
    "        # Update progress\n",
    "        completed_evals += 1\n",
    "        elapsed = time.time() - start_eval_time\n",
    "        rate = completed_evals / elapsed if elapsed > 0 else 0\n",
    "        remaining = (total_evals - completed_evals) / rate if rate > 0 else 0\n",
    "\n",
    "        # Print result with clear formatting, highlight best so far\n",
    "        is_best = (best_model_script['clf_name'] == clf_name_ and\n",
    "                   best_model_script['combo'] == combo_)\n",
    "\n",
    "        best_marker = \"★ \" if is_best else \"  \"\n",
    "\n",
    "        print(f\"{best_marker}{clf_name_:15} | \"\n",
    "              f\"F1: {metrics_['f1']:.4f} | \"\n",
    "              f\"Acc: {metrics_['accuracy']:.4f} | \"\n",
    "              f\"Prec: {metrics_['precision']:.4f} | \"\n",
    "              f\"Rec: {metrics_['recall']:.4f} | \"\n",
    "              f\"Time: {total_t_:.1f}s\")\n",
    "\n",
    "logger.info(\"All models evaluated successfully.\")"
   ],
   "id": "6abf46b9f16d47a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a summary table\n",
    "summary_table = []\n",
    "for combo_key, model_dict in all_results.items():\n",
    "    for model_k, model_res in model_dict.items():\n",
    "        summary_table.append({\n",
    "            'Feature Combo': combo_key,\n",
    "            'Model': model_k,\n",
    "            'Accuracy': f\"{model_res['test_performance']['accuracy']:.4f}\",\n",
    "            'Precision': f\"{model_res['test_performance']['precision']:.4f}\",\n",
    "            'Recall': f\"{model_res['test_performance']['recall']:.4f}\",\n",
    "            'F1 Score': f\"{model_res['test_performance']['f1']:.4f}\",\n",
    "            'ROC AUC': (\n",
    "                f\"{model_res['test_performance']['roc_auc']:.4f}\"\n",
    "                if model_res['test_performance']['roc_auc'] is not None\n",
    "                else 'N/A'\n",
    "            )\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_table)"
   ],
   "id": "57d935d2607a09ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Print highly visible results banner\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                         RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBEST MODEL: {best_model_script['clf_name']} with {'+'.join(best_model_script['combo'])}\")\n",
    "print(f\"F1 SCORE: {best_model_script['score']:.4f}\")\n",
    "print(f\"ACCURACY: {best_model_script['results']['test_performance']['accuracy']:.4f}\")\n",
    "print(f\"PRECISION: {best_model_script['results']['test_performance']['precision']:.4f}\")\n",
    "print(f\"RECALL: {best_model_script['results']['test_performance']['recall']:.4f}\")"
   ],
   "id": "479e441139352aaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show top 3 models\n",
    "print(\"\\nTOP 3 MODELS BY F1 SCORE:\")\n",
    "top_models = sorted(\n",
    "    [(combo, model, results['test_performance']['f1'])\n",
    "     for combo, models in all_results.items()\n",
    "     for model, results in models.items()],\n",
    "    key=lambda x: x[2], reverse=True\n",
    ")[:3]\n",
    "\n",
    "for i, (combo, model, f1) in enumerate(top_models, 1):\n",
    "    result = all_results[combo][model]['test_performance']\n",
    "    print(f\"{i}. {model} with {combo}\")\n",
    "    print(f\"   F1: {f1:.4f} | Acc: {result['accuracy']:.4f} | \"\n",
    "          f\"Prec: {result['precision']:.4f} | Rec: {result['recall']:.4f}\")"
   ],
   "id": "c96e14054437359d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save results as JSON\n",
    "out_json_ = os.path.join(RESULTS_DIR, 'classification_results.json')\n",
    "with open(out_json_, 'w') as f_:\n",
    "    json.dump(all_results, f_, indent=4)\n",
    "\n",
    "# Save best model\n",
    "model_path_ = os.path.join(MODELS_DIR, 'best_model.joblib')\n",
    "joblib.dump(best_model_script['model'], model_path_)"
   ],
   "id": "9456eb00d54d777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save a detailed report\n",
    "best_report_ = {\n",
    "    'model_summary': {\n",
    "        'name': best_model_script['clf_name'],\n",
    "        'feature_combination': '+'.join(best_model_script['combo']),\n",
    "        'total_features': len(best_model_script['features'])\n",
    "    },\n",
    "    'performance_metrics': best_model_script['results']['test_performance'],\n",
    "    'timing_information': best_model_script['results']['timing'],\n",
    "    'feature_importance': (\n",
    "        dict(zip(\n",
    "            best_model_script['features'],\n",
    "            best_model_script['results']['feature_importance']\n",
    "        )) if best_model_script['results']['feature_importance'] is not None else None\n",
    "    )\n",
    "}\n",
    "report_path_ = os.path.join(RESULTS_DIR, 'detailed_report.json')\n",
    "with open(report_path_, 'w') as f_:\n",
    "    json.dump(best_report_, f_, indent=4)\n",
    "\n",
    "print(\"\\nClassification results and best model saved to disk.\")"
   ],
   "id": "25090f0196626ecb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# VISUALIZATION",
   "id": "1494d9692c854d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"     STAGE 3: VISUALIZATION\")\n",
    "print(\"-\"*70)"
   ],
   "id": "8add285679e3d63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate best model plots\n",
    "# Select features for best model\n",
    "idx_sel_ = []\n",
    "for cat_ in best_model_script['combo']:\n",
    "    for prefix_ in FEATURE_CATEGORIES[cat_]:\n",
    "        if prefix_.endswith('_'):\n",
    "            found_ = [i for i, c in enumerate(feat_cols) if c.startswith(prefix_)]\n",
    "        else:\n",
    "            found_ = [i for i, c in enumerate(feat_cols) if c == prefix_]\n",
    "        idx_sel_.extend(found_)\n",
    "X_test_best_ = X_test[:, idx_sel_]"
   ],
   "id": "5d382ba7ab5863fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get predictions\n",
    "y_pred_best_ = best_model_script['model'].predict(X_test_best_)\n",
    "y_proba_best_ = None\n",
    "if hasattr(best_model_script['model'].named_steps['classifier'], 'predict_proba'):\n",
    "    if best_model_script['clf_name'] in CLASSIFIERS and CLASSIFIERS[best_model_script['clf_name']]['expects_proba']:\n",
    "        y_proba_best_ = best_model_script['model'].predict_proba(X_test_best_)[:,1]"
   ],
   "id": "2656a360f736acf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot confusion matrix\n",
    "print(\"Generating confusion matrix...\")\n",
    "cm_path_ = os.path.join(PLOTS_DIR, 'best_model_confusion_matrix.png')\n",
    "cm_ = confusion_matrix(y_test, y_pred_best_)\n",
    "classes_ = ['Normal', 'Defect']\n",
    "disp_ = ConfusionMatrixDisplay(cm_, display_labels=classes_)\n",
    "fig_, ax_ = plt.subplots(figsize=(8, 7))\n",
    "disp_.plot(ax=ax_, cmap=plt.cm.Blues, colorbar=False)\n",
    "plt.title(f\"Confusion Matrix - {best_model_script['clf_name']} with {'+'.join(best_model_script['combo'])}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_path_)\n",
    "plt.close()"
   ],
   "id": "33a859e73c17755b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Print confusion matrix values\n",
    "tn, fp, fn, tp = cm_.ravel()\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives (Normal correctly predicted): {tn}\")\n",
    "print(f\"  False Positives (Normal incorrectly as Defect): {fp}\")\n",
    "print(f\"  False Negatives (Defect incorrectly as Normal): {fn}\")\n",
    "print(f\"  True Positives (Defect correctly predicted): {tp}\")"
   ],
   "id": "c5596bde4e75fa67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot ROC curve if probability estimates available\n",
    "if y_proba_best_ is not None:\n",
    "    print(\"Generating ROC curve...\")\n",
    "    roc_path_ = os.path.join(PLOTS_DIR, 'best_model_roc_curve.png')\n",
    "    disp_ = RocCurveDisplay.from_predictions(y_test, y_proba_best_)\n",
    "    fig_ = disp_.figure_\n",
    "    plt.title(f\"ROC Curve - {best_model_script['clf_name']} with {'+'.join(best_model_script['combo'])}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_path_)\n",
    "    plt.close()"
   ],
   "id": "6d25ac61a187ecb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot feature importances if available\n",
    "if best_model_script['results']['feature_importance'] is not None:\n",
    "    print(\"Generating feature importance visualization...\")\n",
    "    fi_path_ = os.path.join(PLOTS_DIR, 'best_model_feature_importances.png')\n",
    "    fi_abs_ = np.abs(np.array(best_model_script['results']['feature_importance']))\n",
    "    idx_sorted_ = np.argsort(fi_abs_)[::-1]\n",
    "    top_n = min(15, len(fi_abs_))\n",
    "    fi_sorted_ = fi_abs_[idx_sorted_][:top_n]\n",
    "    names_sorted_ = [best_model_script['features'][i] for i in idx_sorted_[:top_n]]\n",
    "\n",
    "    fig_, ax_ = plt.subplots(figsize=(10, 8))\n",
    "    y_pos_ = np.arange(len(fi_sorted_))\n",
    "    ax_.barh(y_pos_, fi_sorted_[::-1], align='center', color='skyblue')\n",
    "    ax_.set_yticks(y_pos_)\n",
    "    ax_.set_yticklabels(names_sorted_[::-1])\n",
    "    ax_.invert_yaxis()\n",
    "    ax_.set_xlabel('Importance')\n",
    "    ax_.set_title(f'Feature Importances - Top {top_n}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fi_path_)\n",
    "    plt.close()\n",
    "\n",
    "    # Print top features\n",
    "    print(\"\\nTop 5 Most Important Features:\")\n",
    "    for i in range(min(5, top_n)):\n",
    "        print(f\"  {i+1}. {names_sorted_[i]}: {fi_sorted_[i]:.4f}\")"
   ],
   "id": "38f98b43ccf7ee17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FINAL SUMMARY",
   "id": "e2356170050ac5de"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T02:30:24.281852Z",
     "start_time": "2025-03-20T02:10:20.607502Z"
    }
   },
   "source": [
    "# Calculate final resource usage\n",
    "cpu_usage_after = psutil.cpu_percent(interval=None)\n",
    "mem_info_after = process.memory_info()\n",
    "memory_usage_mb_after = mem_info_after.rss / 1024 / 1024\n",
    "\n",
    "total_time_script = time.time() - start_time_script\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    PIPELINE COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total execution time: {total_time_script:.1f} seconds ({total_time_script/60:.1f} minutes)\")\n",
    "print(f\"Memory usage: {memory_usage_mb_before:.1f}MB → {memory_usage_mb_after:.1f}MB\")\n",
    "print(f\"All results saved to: {RESULTS_DIR}\")\n",
    "print(\"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Starting coffee bean classification pipeline\n",
      ">>> Feature Extraction started\n",
      ">>> Processing 280 images from Normal/Dry/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "     COFFEE BEAN CLASSIFICATION WITH TRADITIONAL MACHINE LEARNING\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "     STAGE 1: FEATURE EXTRACTION\n",
      "----------------------------------------------------------------------\n",
      "Total images to process: 5400\n",
      "Starting feature extraction (this may take some time)...\n",
      "Processing 280 images from Normal/Dry/Dark/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Dry/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 50.2 seconds (5.6 img/sec)\n",
      "Processing 120 images from Normal/Dry/Dark/test\n",
      "Progress: 337/5400 images (6.2%), Rate: 5.6 img/sec, Est. remaining: 15.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Dry/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 20.7 seconds (5.8 img/sec)\n",
      "Processing 280 images from Normal/Dry/Light/train\n",
      "Progress: 626/5400 images (11.6%), Rate: 4.8 img/sec, Est. remaining: 16.6 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Dry/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 59.6 seconds (4.7 img/sec)\n",
      "Processing 120 images from Normal/Dry/Light/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Dry/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 23.2 seconds (5.2 img/sec)\n",
      "Processing 280 images from Normal/Dry/Medium/train\n",
      "Progress: 948/5400 images (17.6%), Rate: 5.4 img/sec, Est. remaining: 13.8 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Dry/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 52.1 seconds (5.4 img/sec)\n",
      "Processing 120 images from Normal/Dry/Medium/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Honey/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 24.0 seconds (5.0 img/sec)\n",
      "Processing 280 images from Normal/Honey/Dark/train\n",
      "Progress: 1259/5400 images (23.3%), Rate: 5.2 img/sec, Est. remaining: 13.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Honey/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 50.8 seconds (5.5 img/sec)\n",
      "Processing 120 images from Normal/Honey/Dark/test\n",
      "Progress: 1590/5400 images (29.4%), Rate: 5.5 img/sec, Est. remaining: 11.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Honey/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 21.7 seconds (5.5 img/sec)\n",
      "Processing 280 images from Normal/Honey/Light/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Honey/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 50.3 seconds (5.6 img/sec)\n",
      "Processing 120 images from Normal/Honey/Light/test\n",
      "Progress: 1925/5400 images (35.6%), Rate: 5.6 img/sec, Est. remaining: 10.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Honey/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 20.2 seconds (5.9 img/sec)\n",
      "Processing 280 images from Normal/Honey/Medium/train\n",
      "Progress: 2255/5400 images (41.8%), Rate: 5.5 img/sec, Est. remaining: 9.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Honey/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 51.9 seconds (5.4 img/sec)\n",
      "Processing 120 images from Normal/Honey/Medium/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Wet/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 19.7 seconds (6.1 img/sec)\n",
      "Processing 280 images from Normal/Wet/Dark/train\n",
      "Progress: 2614/5400 images (48.4%), Rate: 6.0 img/sec, Est. remaining: 7.8 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Wet/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 47.5 seconds (5.9 img/sec)\n",
      "Processing 120 images from Normal/Wet/Dark/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Wet/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 20.8 seconds (5.8 img/sec)\n",
      "Processing 280 images from Normal/Wet/Light/train\n",
      "Progress: 2964/5400 images (54.9%), Rate: 5.8 img/sec, Est. remaining: 7.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Wet/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 47.5 seconds (5.9 img/sec)\n",
      "Processing 120 images from Normal/Wet/Light/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 280 images from Normal/Wet/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 22.5 seconds (5.3 img/sec)\n",
      "Processing 280 images from Normal/Wet/Medium/train\n",
      "Progress: 3298/5400 images (61.1%), Rate: 5.6 img/sec, Est. remaining: 6.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 120 images from Normal/Wet/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 51.8 seconds (5.4 img/sec)\n",
      "Processing 120 images from Normal/Wet/Medium/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Dry/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 22.0 seconds (5.5 img/sec)\n",
      "Processing 140 images from Defect/Dry/Dark/train\n",
      "Progress: 3623/5400 images (67.1%), Rate: 5.4 img/sec, Est. remaining: 5.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Dry/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 27.2 seconds (5.2 img/sec)\n",
      "Processing 60 images from Defect/Dry/Dark/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Dry/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 13.1 seconds (4.6 img/sec)\n",
      "Processing 140 images from Defect/Dry/Light/train\n",
      "Progress: 3906/5400 images (72.3%), Rate: 4.7 img/sec, Est. remaining: 5.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Dry/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 31.7 seconds (4.4 img/sec)\n",
      "Processing 60 images from Defect/Dry/Light/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Dry/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 13.7 seconds (4.4 img/sec)\n",
      "Processing 140 images from Defect/Dry/Medium/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Dry/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 29.2 seconds (4.8 img/sec)\n",
      "Processing 60 images from Defect/Dry/Medium/test\n",
      "Progress: 4184/5400 images (77.5%), Rate: 4.6 img/sec, Est. remaining: 4.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Honey/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 13.1 seconds (4.6 img/sec)\n",
      "Processing 140 images from Defect/Honey/Dark/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Honey/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 26.9 seconds (5.2 img/sec)\n",
      "Processing 60 images from Defect/Honey/Dark/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Honey/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 11.9 seconds (5.0 img/sec)\n",
      "Processing 140 images from Defect/Honey/Light/train\n",
      "Progress: 4494/5400 images (83.2%), Rate: 5.2 img/sec, Est. remaining: 2.9 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Honey/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 25.1 seconds (5.6 img/sec)\n",
      "Processing 60 images from Defect/Honey/Light/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Honey/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 9.7 seconds (6.2 img/sec)\n",
      "Processing 140 images from Defect/Honey/Medium/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Honey/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 22.5 seconds (6.2 img/sec)\n",
      "Processing 60 images from Defect/Honey/Medium/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Wet/Dark/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 9.9 seconds (6.0 img/sec)\n",
      "Processing 140 images from Defect/Wet/Dark/train\n",
      "Progress: 4864/5400 images (90.1%), Rate: 6.2 img/sec, Est. remaining: 1.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Wet/Dark/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 23.5 seconds (6.0 img/sec)\n",
      "Processing 60 images from Defect/Wet/Dark/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Wet/Light/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 10.3 seconds (5.8 img/sec)\n",
      "Processing 140 images from Defect/Wet/Light/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Wet/Light/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 23.8 seconds (5.9 img/sec)\n",
      "Processing 60 images from Defect/Wet/Light/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 140 images from Defect/Wet/Medium/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 11.0 seconds (5.5 img/sec)\n",
      "Processing 140 images from Defect/Wet/Medium/train\n",
      "Progress: 5212/5400 images (96.5%), Rate: 5.8 img/sec, Est. remaining: 0.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Processing 60 images from Defect/Wet/Medium/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch in 24.6 seconds (5.7 img/sec)\n",
      "Processing 60 images from Defect/Wet/Medium/test\n",
      "Completed batch in 10.5 seconds (5.7 img/sec)\n",
      "Feature extraction completed\n",
      "Scaling features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Classification stage started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "                  FEATURE EXTRACTION SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Total samples: 5400 images\n",
      "Feature dimensionality: 182 features\n",
      "  - Color features (correlogram): 117 dimensions\n",
      "  - Texture features (GLCM): 60 dimensions\n",
      "  - Shape features: 5 dimensions\n",
      "\n",
      "Class distribution:\n",
      "  train set => Normal: 2520 , Defect: 1260 \n",
      "  test  set => Normal: 1080 , Defect: 540  \n",
      "\n",
      "Total processing time: 994.4 seconds (5.4 images/sec)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "     STAGE 2: CLASSIFICATION AND MODEL EVALUATION\n",
      "----------------------------------------------------------------------\n",
      "Dataset prepared for classification:\n",
      "  - Train set: 3780 samples\n",
      "  - Test set: 1620 samples\n",
      "  - Features: 182 dimensions\n",
      "\n",
      "Evaluating feature combinations and classifiers...\n",
      "This will test 7 feature combinations × 7 classifiers = 49 models\n",
      "\n",
      "Evaluating feature combination: 'color' (color: 117)\n",
      "★ SVM             | F1: 0.8240 | Acc: 0.8877 | Prec: 0.8623 | Rec: 0.7889 | Time: 9.7s\n",
      "  RandomForest    | F1: 0.6591 | Acc: 0.7969 | Prec: 0.7482 | Rec: 0.5889 | Time: 5.5s\n",
      "  XGBoost         | F1: 0.7237 | Acc: 0.8247 | Prec: 0.7623 | Rec: 0.6889 | Time: 20.3s\n",
      "  ExtraTrees      | F1: 0.6494 | Acc: 0.7994 | Prec: 0.7778 | Rec: 0.5574 | Time: 3.5s\n",
      "  KNN             | F1: 0.6366 | Acc: 0.7815 | Prec: 0.7143 | Rec: 0.5741 | Time: 1.1s\n",
      "  DecisionTree    | F1: 0.5900 | Acc: 0.7358 | Prec: 0.6111 | Rec: 0.5704 | Time: 1.0s\n",
      "\n",
      "Evaluating feature combination: 'texture' (texture: 60)\n",
      "  SVM             | F1: 0.7388 | Acc: 0.8420 | Prec: 0.8227 | Rec: 0.6704 | Time: 5.7s\n",
      "  RandomForest    | F1: 0.6135 | Acc: 0.7815 | Prec: 0.7473 | Rec: 0.5204 | Time: 3.2s\n",
      "  XGBoost         | F1: 0.6790 | Acc: 0.8074 | Prec: 0.7639 | Rec: 0.6111 | Time: 8.9s\n",
      "  ExtraTrees      | F1: 0.5718 | Acc: 0.7660 | Prec: 0.7333 | Rec: 0.4685 | Time: 2.3s\n",
      "  KNN             | F1: 0.5888 | Acc: 0.7698 | Prec: 0.7275 | Rec: 0.4944 | Time: 0.5s\n",
      "  DecisionTree    | F1: 0.5874 | Acc: 0.7407 | Prec: 0.6255 | Rec: 0.5537 | Time: 0.6s\n",
      "\n",
      "Evaluating feature combination: 'shape' (shape: 5)\n",
      "  SVM             | F1: 0.5721 | Acc: 0.7747 | Prec: 0.7796 | Rec: 0.4519 | Time: 4.0s\n",
      "  RandomForest    | F1: 0.6090 | Acc: 0.7796 | Prec: 0.7453 | Rec: 0.5148 | Time: 2.1s\n",
      "  XGBoost         | F1: 0.6046 | Acc: 0.7537 | Prec: 0.6503 | Rec: 0.5648 | Time: 2.0s\n",
      "  ExtraTrees      | F1: 0.5013 | Acc: 0.7593 | Prec: 0.8099 | Rec: 0.3630 | Time: 1.8s\n",
      "  KNN             | F1: 0.5632 | Acc: 0.7568 | Prec: 0.7017 | Rec: 0.4704 | Time: 0.2s\n",
      "  DecisionTree    | F1: 0.5858 | Acc: 0.7407 | Prec: 0.6266 | Rec: 0.5500 | Time: 0.1s\n",
      "\n",
      "Evaluating feature combination: 'color+texture' (color: 117, texture: 60)\n",
      "★ SVM             | F1: 0.8374 | Acc: 0.8981 | Prec: 0.8947 | Rec: 0.7870 | Time: 6.1s\n",
      "  RandomForest    | F1: 0.6660 | Acc: 0.8062 | Prec: 0.7825 | Rec: 0.5796 | Time: 3.9s\n",
      "  XGBoost         | F1: 0.7280 | Acc: 0.8302 | Prec: 0.7813 | Rec: 0.6815 | Time: 26.1s\n",
      "  ExtraTrees      | F1: 0.6572 | Acc: 0.8056 | Prec: 0.7968 | Rec: 0.5593 | Time: 2.4s\n",
      "  KNN             | F1: 0.6210 | Acc: 0.7815 | Prec: 0.7360 | Rec: 0.5370 | Time: 0.6s\n",
      "  DecisionTree    | F1: 0.5835 | Acc: 0.7321 | Prec: 0.6056 | Rec: 0.5630 | Time: 1.4s\n",
      "\n",
      "Evaluating feature combination: 'color+shape' (color: 117, shape: 5)\n",
      "★ SVM             | F1: 0.8420 | Acc: 0.9006 | Prec: 0.8956 | Rec: 0.7944 | Time: 6.2s\n",
      "  RandomForest    | F1: 0.6865 | Acc: 0.8179 | Prec: 0.8055 | Rec: 0.5981 | Time: 4.3s\n",
      "  XGBoost         | F1: 0.7671 | Acc: 0.8568 | Prec: 0.8377 | Rec: 0.7074 | Time: 17.3s\n",
      "  ExtraTrees      | F1: 0.6608 | Acc: 0.8093 | Prec: 0.8113 | Rec: 0.5574 | Time: 2.4s\n",
      "  KNN             | F1: 0.6519 | Acc: 0.7969 | Prec: 0.7605 | Rec: 0.5704 | Time: 0.4s\n",
      "  DecisionTree    | F1: 0.6563 | Acc: 0.7809 | Prec: 0.6876 | Rec: 0.6278 | Time: 1.0s\n",
      "\n",
      "Evaluating feature combination: 'texture+shape' (texture: 60, shape: 5)\n",
      "  SVM             | F1: 0.7984 | Acc: 0.8765 | Prec: 0.8761 | Rec: 0.7333 | Time: 4.8s\n",
      "  RandomForest    | F1: 0.6281 | Acc: 0.7938 | Prec: 0.7877 | Rec: 0.5222 | Time: 3.7s\n",
      "  XGBoost         | F1: 0.7388 | Acc: 0.8420 | Prec: 0.8227 | Rec: 0.6704 | Time: 9.4s\n",
      "  ExtraTrees      | F1: 0.6129 | Acc: 0.7895 | Prec: 0.7918 | Rec: 0.5000 | Time: 2.5s\n",
      "  KNN             | F1: 0.5966 | Acc: 0.7821 | Prec: 0.7791 | Rec: 0.4833 | Time: 0.5s\n",
      "  DecisionTree    | F1: 0.6052 | Acc: 0.7488 | Prec: 0.6354 | Rec: 0.5778 | Time: 0.7s\n",
      "\n",
      "Evaluating feature combination: 'color+texture+shape' (color: 117, texture: 60, shape: 5)\n",
      "★ SVM             | F1: 0.8608 | Acc: 0.9123 | Prec: 0.9146 | Rec: 0.8130 | Time: 6.4s\n",
      "  RandomForest    | F1: 0.6774 | Acc: 0.8142 | Prec: 0.8041 | Rec: 0.5852 | Time: 4.5s\n",
      "  XGBoost         | F1: 0.7734 | Acc: 0.8611 | Prec: 0.8477 | Rec: 0.7111 | Time: 24.5s\n",
      "  ExtraTrees      | F1: 0.6659 | Acc: 0.8123 | Prec: 0.8189 | Rec: 0.5611 | Time: 2.6s\n",
      "  KNN             | F1: 0.6335 | Acc: 0.7907 | Prec: 0.7610 | Rec: 0.5426 | Time: 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> All models evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DecisionTree    | F1: 0.5955 | Acc: 0.7451 | Prec: 0.6320 | Rec: 0.5630 | Time: 1.5s\n",
      "\n",
      "======================================================================\n",
      "                         RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "BEST MODEL: SVM with color+texture+shape\n",
      "F1 SCORE: 0.8608\n",
      "ACCURACY: 0.9123\n",
      "PRECISION: 0.9146\n",
      "RECALL: 0.8130\n",
      "\n",
      "TOP 3 MODELS BY F1 SCORE:\n",
      "1. SVM with color+texture+shape\n",
      "   F1: 0.8608 | Acc: 0.9123 | Prec: 0.9146 | Rec: 0.8130\n",
      "2. SVM with color+shape\n",
      "   F1: 0.8420 | Acc: 0.9006 | Prec: 0.8956 | Rec: 0.7944\n",
      "3. SVM with color+texture\n",
      "   F1: 0.8374 | Acc: 0.8981 | Prec: 0.8947 | Rec: 0.7870\n",
      "\n",
      "Classification results and best model saved to disk.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "     STAGE 3: VISUALIZATION\n",
      "----------------------------------------------------------------------\n",
      "Generating confusion matrix...\n",
      "\n",
      "Confusion Matrix:\n",
      "  True Negatives (Normal correctly predicted): 1039\n",
      "  False Positives (Normal incorrectly as Defect): 41\n",
      "  False Negatives (Defect incorrectly as Normal): 101\n",
      "  True Positives (Defect correctly predicted): 439\n",
      "Generating ROC curve...\n",
      "\n",
      "======================================================================\n",
      "                    PIPELINE COMPLETED\n",
      "======================================================================\n",
      "Total execution time: 1202.1 seconds (20.0 minutes)\n",
      "Memory usage: 215.5MB → 558.8MB\n",
      "All results saved to: D:\\iate_project\\ml_output\\ml_classification_results\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T08:35:31.375805Z",
     "start_time": "2025-04-08T08:29:59.383509Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, make_scorer\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set font properties for academic-style plots\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "# Record script start time\n",
    "start_time_script = time.time()\n",
    "\n",
    "# Global Configuration\n",
    "ROOT_DIR = \"D:\\\\iate_project\\\\data\\\\\"\n",
    "DL_MODEL_DIR = os.path.join(ROOT_DIR, \"results\", \"dl_output\", \"dl_training\", \"models\")\n",
    "HYBRID_OUTPUT_DIR = os.path.join(ROOT_DIR, \"results\", \"hybrid_output\")\n",
    "HYBRID_FEATURE_DIR = os.path.join(HYBRID_OUTPUT_DIR, \"features\")\n",
    "HYBRID_RESULTS_DIR = os.path.join(HYBRID_OUTPUT_DIR, \"results\")\n",
    "HYBRID_MODELS_DIR = os.path.join(HYBRID_RESULTS_DIR, \"models\")\n",
    "HYBRID_PLOTS_DIR = os.path.join(HYBRID_RESULTS_DIR, \"plots\")\n",
    "\n",
    "# Path to original dataset\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"raw\")\n",
    "\n",
    "# Create necessary directories\n",
    "for d in [HYBRID_OUTPUT_DIR, HYBRID_FEATURE_DIR, HYBRID_RESULTS_DIR, HYBRID_MODELS_DIR, HYBRID_PLOTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Hyperparameter tuning settings\n",
    "N_ITER_SEARCH = 15  # Number of parameter settings sampled in RandomizedSearchCV\n",
    "CV_FOLDS = 5        # Number of cross-validation folds for hyperparameter tuning\n",
    "\n",
    "# Define base classifiers for hyperparameter optimization\n",
    "BASE_CLASSIFIERS = {\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42, cache_size=1000),\n",
    "        'param_dist': {\n",
    "            'C': uniform(50, 200),\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "            'kernel': ['rbf', 'poly']\n",
    "        },\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "        'param_dist': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        },\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(objective='binary:logistic', random_state=42, n_jobs=-1),\n",
    "        'param_dist': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "            'max_depth': randint(3, 10),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4)\n",
    "        },\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'model': ExtraTreesClassifier(n_jobs=-1, random_state=42),\n",
    "        'param_dist': {\n",
    "            'n_estimators': randint(100, 600),\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        },\n",
    "        'expects_proba': True\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(n_jobs=-1),\n",
    "        'param_dist': {\n",
    "            'n_neighbors': randint(3, 15),\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "        },\n",
    "        'expects_proba': True,\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'param_dist': {\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        },\n",
    "        'expects_proba': True\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"HYBRID APPROACH: DEEP FEATURES + ML CLASSIFIERS\")\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# STAGE 1: DEEP FEATURE EXTRACTION\n",
    "#-------------------------------------------------------------\n",
    "print(\"STAGE 1: DEEP FEATURE EXTRACTION\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the mobilevit_xs model (best model from DL experiment)\n",
    "model_path = os.path.join(DL_MODEL_DIR, \"mobilevit_xs_final_model.pth\")\n",
    "model = timm.create_model('mobilevit_xs', pretrained=False, num_classes=2)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Create a feature extractor by removing the classification head\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Get all layers except the final classifier\n",
    "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get features\n",
    "        x = self.features(x)\n",
    "        # Global average pooling\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "# Create feature extractor and move to device\n",
    "feature_extractor = FeatureExtractor(model)\n",
    "feature_extractor.to(device)\n",
    "feature_extractor.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define image transformation (same as used in DL training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Lists to hold extracted data\n",
    "features_list = []\n",
    "labels = []\n",
    "paths = []\n",
    "splits = []\n",
    "\n",
    "# Define train/test split ratio (70% train, 30% test)\n",
    "train_ratio = 0.7\n",
    "\n",
    "extraction_start_time = time.time()\n",
    "\n",
    "# Create storage for class distribution info\n",
    "class_counts = {'train': {'normal': 0, 'defect': 0},\n",
    "               'test': {'normal': 0, 'defect': 0}}\n",
    "\n",
    "# Process image directories\n",
    "classes = ['normal', 'defect']\n",
    "processing_types = ['dry', 'honey', 'wet']\n",
    "roast_levels = ['dark', 'light', 'medium']\n",
    "\n",
    "# Count total files for progress tracking\n",
    "total_files_count = 0\n",
    "for class_name in classes:\n",
    "    for proc_type in processing_types:\n",
    "        for roast in roast_levels:\n",
    "            subfolder_path = os.path.join(DATASET_PATH, class_name, proc_type, roast)\n",
    "            if os.path.exists(subfolder_path):\n",
    "                image_files = [f for f in os.listdir(subfolder_path)\n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                total_files_count += len(image_files)\n",
    "\n",
    "print(f\"Total images to process: {total_files_count}\")\n",
    "\n",
    "# Process images\n",
    "with torch.no_grad():  # No gradient computation needed\n",
    "    for class_name in classes:\n",
    "        for proc_type in processing_types:\n",
    "            for roast in roast_levels:\n",
    "                # Construct the path to the current subfolder\n",
    "                subfolder_path = os.path.join(DATASET_PATH, class_name, proc_type, roast)\n",
    "\n",
    "                if not os.path.exists(subfolder_path):\n",
    "                    continue\n",
    "\n",
    "                # Get list of image files in the current subfolder\n",
    "                image_files = [f for f in os.listdir(subfolder_path)\n",
    "                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "                if not image_files:\n",
    "                    continue\n",
    "\n",
    "                # Shuffle files for random split\n",
    "                np.random.seed(42)  # For reproducibility\n",
    "                np.random.shuffle(image_files)\n",
    "\n",
    "                # Split into train and test\n",
    "                split_idx = int(len(image_files) * train_ratio)\n",
    "                train_files = image_files[:split_idx]\n",
    "                test_files = image_files[split_idx:]\n",
    "\n",
    "                # Update class distribution counts\n",
    "                class_counts['train'][class_name] += len(train_files)\n",
    "                class_counts['test'][class_name] += len(test_files)\n",
    "\n",
    "                # Process each split\n",
    "                for split_name, files in [('train', train_files), ('test', test_files)]:\n",
    "                    batch_size = len(files)\n",
    "\n",
    "                    # Process each image\n",
    "                    for file_ in files:\n",
    "                        # Construct full path to the image\n",
    "                        img_path = os.path.join(subfolder_path, file_)\n",
    "\n",
    "                        try:\n",
    "                            # Open and preprocess image\n",
    "                            img = Image.open(img_path).convert('RGB')\n",
    "                            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "                            # Extract features\n",
    "                            feat = feature_extractor(img_tensor)\n",
    "\n",
    "                            # Add to lists\n",
    "                            features_list.append(feat.cpu().numpy().flatten())\n",
    "                            labels.append(class_name)\n",
    "                            paths.append(os.path.join(class_name, proc_type, roast, file_))\n",
    "                            splits.append(split_name)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            pass\n",
    "\n",
    "# Create DataFrame\n",
    "feature_dim = features_list[0].shape[0]\n",
    "feat_names = [f'deep_feature_{i}' for i in range(feature_dim)]\n",
    "\n",
    "df = pd.DataFrame(features_list, columns=feat_names)\n",
    "df['label'] = labels\n",
    "df['image_path'] = paths\n",
    "df['split'] = splits\n",
    "\n",
    "# Split and scale\n",
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] == 'test']\n",
    "scaler = StandardScaler()\n",
    "train_mat = scaler.fit_transform(train_df[feat_names])\n",
    "test_mat = scaler.transform(test_df[feat_names])\n",
    "df.loc[df['split'] == 'train', feat_names] = train_mat\n",
    "df.loc[df['split'] == 'test', feat_names] = test_mat\n",
    "\n",
    "# Save scaler info\n",
    "sc_info = {\n",
    "    'mean': scaler.mean_.tolist(),\n",
    "    'scale': scaler.scale_.tolist(),\n",
    "    'feature_names': feat_names\n",
    "}\n",
    "with open(os.path.join(HYBRID_FEATURE_DIR, 'scaler_params.json'), 'w') as f:\n",
    "    json.dump(sc_info, f, indent=4)\n",
    "\n",
    "# Save CSV of extracted features\n",
    "output_csv_path = os.path.join(HYBRID_FEATURE_DIR, 'deep_features.csv')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "extraction_time = time.time() - extraction_start_time\n",
    "\n",
    "# Build metadata\n",
    "class_dist = df.groupby(['split', 'label']).size()\n",
    "class_dist_dict = {\n",
    "    f\"{sp}_{lb}\": int(cnt)\n",
    "    for (sp, lb), cnt in class_dist.items()\n",
    "}\n",
    "\n",
    "meta = {\n",
    "    'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'processing_time': {\n",
    "        'total_time': f\"{extraction_time:.2f} seconds\",\n",
    "        'per_image': f\"{extraction_time/len(df):.4f} seconds/image\"\n",
    "    },\n",
    "    'dataset_statistics': {\n",
    "        'total_samples': len(df),\n",
    "        'class_distribution': class_dist_dict,\n",
    "        'feature_dimensions': feature_dim\n",
    "    },\n",
    "    'model_info': {\n",
    "        'architecture': 'mobilevit_xs',\n",
    "        'feature_layer': 'before_classifier'\n",
    "    }\n",
    "}\n",
    "\n",
    "meta_path = os.path.join(HYBRID_FEATURE_DIR, 'extraction_metadata.json')\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(meta, f, indent=4)\n",
    "\n",
    "# Print extraction summary\n",
    "print(\"DEEP FEATURE EXTRACTION COMPLETE\")\n",
    "print(f\"Total samples: {len(df)} images\")\n",
    "print(f\"Feature dimensionality: {feature_dim} features\")\n",
    "print(f\"Processing time: {extraction_time:.1f} seconds ({len(df)/extraction_time:.1f} images/sec)\")\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# STAGE 2: TRAIN ML CLASSIFIERS ON DEEP FEATURES\n",
    "#-------------------------------------------------------------\n",
    "print(\"STAGE 2: TRAIN ML CLASSIFIERS ON DEEP FEATURES\")\n",
    "\n",
    "# Prepare data for classification\n",
    "feat_cols = [c for c in df.columns if c.startswith('deep_feature_')]\n",
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] == 'test']\n",
    "\n",
    "X_train = train_df[feat_cols].values\n",
    "X_test = test_df[feat_cols].values\n",
    "label_map = {'normal': 0, 'defect': 1}\n",
    "y_train = np.array([label_map[l] for l in train_df['label']])\n",
    "y_test = np.array([label_map[l] for l in test_df['label']])\n",
    "\n",
    "# Setup for results collection\n",
    "all_results = {}\n",
    "best_model_info = {\n",
    "    'score': -1,\n",
    "    'clf_name': None,\n",
    "    'model': None,\n",
    "    'results': None,\n",
    "    'best_params': None\n",
    "}\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf_info in BASE_CLASSIFIERS.items():\n",
    "    eval_start = time.time()\n",
    "\n",
    "    # Create a pipeline with the classifier\n",
    "    pipeline = clf_info['model']\n",
    "\n",
    "    # Setup parameter distributions\n",
    "    param_dist = clf_info['param_dist']\n",
    "\n",
    "    # Create RandomizedSearchCV for hyperparameter tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=N_ITER_SEARCH,\n",
    "        cv=CV_FOLDS,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Fit RandomizedSearchCV to find best parameters\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get best model and parameters\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    # Cross-validation with best model\n",
    "    cv_metrics = {}\n",
    "    splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, zero_division=0),\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1',\n",
    "        'roc_auc': 'roc_auc'\n",
    "    }\n",
    "    cv_results = cross_validate(\n",
    "        best_model, X_train, y_train,\n",
    "        scoring=scoring, cv=splitter, n_jobs=-1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Process CV results\n",
    "    for metric, scores in [(k.replace('test_', ''), cv_results[k])\n",
    "                        for k in cv_results if k.startswith('test_')]:\n",
    "        cv_metrics[metric] = {\n",
    "            'mean': float(scores.mean()),\n",
    "            'std': float(scores.std()),\n",
    "            'values': scores.tolist()\n",
    "        }\n",
    "\n",
    "    # Predict test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = None\n",
    "    if clf_info['expects_proba']:\n",
    "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute test metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    }\n",
    "\n",
    "    # Get feature importances if available\n",
    "    feat_imp = None\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feat_imp = best_model.feature_importances_\n",
    "    elif hasattr(best_model, 'coef_'):\n",
    "        feat_imp = np.abs(best_model.coef_[0])\n",
    "\n",
    "    # Record total time\n",
    "    total_t = time.time() - eval_start\n",
    "\n",
    "    # Store results\n",
    "    result_dict = {\n",
    "        'model_name': clf_name,\n",
    "        'cross_validation': cv_metrics,\n",
    "        'test_performance': metrics,\n",
    "        'timing': {\n",
    "            'total_time': total_t\n",
    "        },\n",
    "        'feature_importance': feat_imp.tolist() if feat_imp is not None else None,\n",
    "        'best_params': best_params\n",
    "    }\n",
    "    all_results[clf_name] = result_dict\n",
    "\n",
    "    # Track the best model by F1 score\n",
    "    cur_f1 = metrics['f1']\n",
    "    if cur_f1 > best_model_info['score']:\n",
    "        best_model_info['score'] = cur_f1\n",
    "        best_model_info['clf_name'] = clf_name\n",
    "        best_model_info['model'] = best_model\n",
    "        best_model_info['results'] = result_dict\n",
    "        best_model_info['best_params'] = best_params\n",
    "\n",
    "    # Print result with clear formatting\n",
    "    is_best = (best_model_info['clf_name'] == clf_name)\n",
    "    best_marker = \"★ \" if is_best else \"  \"\n",
    "\n",
    "    print(f\"{best_marker}{clf_name:15} | \"\n",
    "          f\"F1: {metrics['f1']:.4f} | \"\n",
    "          f\"Acc: {metrics['accuracy']:.4f} | \"\n",
    "          f\"Prec: {metrics['precision']:.4f} | \"\n",
    "          f\"Rec: {metrics['recall']:.4f}\")\n",
    "\n",
    "# Save results as JSON\n",
    "out_json = os.path.join(HYBRID_RESULTS_DIR, 'classification_results.json')\n",
    "with open(out_json, 'w') as f:\n",
    "    json.dump(all_results, f, indent=4)\n",
    "\n",
    "# Save best model\n",
    "model_path = os.path.join(HYBRID_MODELS_DIR, 'best_model.joblib')\n",
    "joblib.dump(best_model_info['model'], model_path)\n",
    "\n",
    "# Save a detailed report\n",
    "best_report = {\n",
    "    'model_summary': {\n",
    "        'name': best_model_info['clf_name'],\n",
    "        'feature_type': 'deep_features',\n",
    "        'total_features': len(feat_cols),\n",
    "        'best_hyperparameters': best_model_info['best_params']\n",
    "    },\n",
    "    'performance_metrics': best_model_info['results']['test_performance'],\n",
    "    'timing_information': best_model_info['results']['timing']\n",
    "}\n",
    "report_path = os.path.join(HYBRID_RESULTS_DIR, 'detailed_report.json')\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(best_report, f, indent=4)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# ENHANCED VISUALIZATIONS FOR ACADEMIC PUBLICATION\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "# 1. Enhanced Confusion Matrix\n",
    "cm_path = os.path.join(HYBRID_PLOTS_DIR, 'best_model_confusion_matrix.png')\n",
    "cm = confusion_matrix(y_test, best_model_info['model'].predict(X_test))\n",
    "classes = ['Normal', 'Defect']  # Capitalize class names for publication\n",
    "total_samples = np.sum(cm)\n",
    "\n",
    "# Calculate percentages for annotations\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Create custom colormap for better visualization\n",
    "colors = [\"#f7fbff\", \"#08306b\"]  # From light blue to dark blue\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_blues\", colors, N=100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Add title and axis labels\n",
    "ax.set_title(f'Confusion Matrix - {best_model_info[\"clf_name\"]} with Deep Features',\n",
    "             fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Predicted Label', fontweight='bold', labelpad=15)\n",
    "ax.set_ylabel('True Label', fontweight='bold', labelpad=15)\n",
    "\n",
    "# Add tick marks and labels\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "\n",
    "# Rotate the tick labels and set alignment\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations with counts and percentages\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        if i == j:\n",
    "            color = \"white\"  # For diagonal elements (correctly classified)\n",
    "        else:\n",
    "            color = \"black\"\n",
    "\n",
    "        # Format as count (percentage)\n",
    "        percentage = cm_norm[i, j] * 100\n",
    "        text = f\"{cm[i, j]}\\n({percentage:.1f}%)\"\n",
    "\n",
    "        ax.text(j, i, text, ha=\"center\", va=\"center\",\n",
    "                color=color if cm[i, j] > thresh else \"black\",\n",
    "                fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add overall accuracy and F1 score in the figure\n",
    "accuracy = (tn + tp) / total_samples\n",
    "f1 = best_model_info['results']['test_performance']['f1']\n",
    "precision = best_model_info['results']['test_performance']['precision']\n",
    "recall = best_model_info['results']['test_performance']['recall']\n",
    "\n",
    "# Add performance metrics as text box\n",
    "textstr = '\\n'.join((\n",
    "    f'Accuracy: {accuracy:.4f}',\n",
    "    f'Precision: {precision:.4f}',\n",
    "    f'Recall: {recall:.4f}',\n",
    "    f'F1 Score: {f1:.4f}'))\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "ax.text(1.05, 0.5, textstr, transform=ax.transAxes, fontsize=12,\n",
    "        verticalalignment='center', bbox=props)\n",
    "\n",
    "# Final formatting\n",
    "fig.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Enhanced ROC Curve\n",
    "if best_model_info['results']['test_performance']['roc_auc'] is not None:\n",
    "    roc_path = os.path.join(HYBRID_PLOTS_DIR, 'best_model_roc_curve.png')\n",
    "    y_proba = best_model_info['model'].predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Plot ROC curve\n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        y_test, y_proba,\n",
    "        name=f'{best_model_info[\"clf_name\"]}',\n",
    "        ax=ax,\n",
    "        plot_chance_level=True  # Add diagonal reference line\n",
    "    )\n",
    "\n",
    "    # Get AUC value\n",
    "    auc_value = best_model_info['results']['test_performance']['roc_auc']\n",
    "\n",
    "    # Add title and improve labels\n",
    "    ax.set_title(f'ROC Curve - {best_model_info[\"clf_name\"]} with Deep Features',\n",
    "                 fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('False Positive Rate', fontweight='bold', labelpad=15)\n",
    "    ax.set_ylabel('True Positive Rate', fontweight='bold', labelpad=15)\n",
    "\n",
    "    # Add AUC value to legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = [f'{best_model_info[\"clf_name\"]} (AUC = {auc_value:.4f})', 'Chance level (AUC = 0.5)']\n",
    "    ax.legend(handles, labels, loc='lower right')\n",
    "\n",
    "    # Add grid for better readability\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Format axes with percentage labels\n",
    "    ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "    # Add operating points\n",
    "    thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "        tn_t, fp_t, fn_t, tp_t = confusion_matrix(y_test, y_pred_thresh).ravel()\n",
    "        tpr = tp_t / (tp_t + fn_t)\n",
    "        fpr = fp_t / (fp_t + tn_t)\n",
    "\n",
    "        # Only plot if point is within axis limits\n",
    "        if 0 <= fpr <= 1 and 0 <= tpr <= 1:\n",
    "            ax.plot(fpr, tpr, 'ro', markersize=8)\n",
    "            ax.annotate(f'T={threshold:.1f}',\n",
    "                        xy=(fpr, tpr),\n",
    "                        xytext=(fpr+0.05, tpr-0.05),\n",
    "                        fontsize=10,\n",
    "                        arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Enhanced Performance Comparison Bar Chart\n",
    "try:\n",
    "    # Load previous approach results\n",
    "    ml_results_path = os.path.join(ROOT_DIR, \"results\", \"ml_output\", \"ml_classification_results\", \"detailed_report.json\")\n",
    "    with open(ml_results_path, 'r') as f:\n",
    "        ml_results = json.load(f)\n",
    "\n",
    "    dl_results_path = os.path.join(ROOT_DIR, \"results\", \"dl_output\", \"dl_training\", \"results\", \"final_model_comparison.json\")\n",
    "    with open(dl_results_path, 'r') as f:\n",
    "        dl_results = json.load(f)\n",
    "\n",
    "    # Get best DL model metrics\n",
    "    best_dl_model = dl_results['best_model']\n",
    "    best_dl_metrics = dl_results['models'][best_dl_model]\n",
    "\n",
    "    # Create comparison data\n",
    "    comparison = {\n",
    "        'Pure ML\\n(Handcrafted Features + SVM)': {\n",
    "            'accuracy': float(ml_results['performance_metrics']['accuracy']),\n",
    "            'precision': float(ml_results['performance_metrics']['precision']),\n",
    "            'recall': float(ml_results['performance_metrics']['recall']),\n",
    "            'f1_score': float(ml_results['performance_metrics']['f1']),\n",
    "        },\n",
    "        'Hybrid\\n(Deep Features + ML)': {\n",
    "            'accuracy': float(best_model_info['results']['test_performance']['accuracy']),\n",
    "            'precision': float(best_model_info['results']['test_performance']['precision']),\n",
    "            'recall': float(best_model_info['results']['test_performance']['recall']),\n",
    "            'f1_score': float(best_model_info['results']['test_performance']['f1']),\n",
    "        },\n",
    "        'Pure DL\\n(End-to-End Deep Learning)': {\n",
    "            'accuracy': float(best_dl_metrics['accuracy']),\n",
    "            'precision': float(best_dl_metrics['precision']),\n",
    "            'recall': float(best_dl_metrics['recall']),\n",
    "            'f1_score': float(best_dl_metrics['f1_score']),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save comparison as JSON\n",
    "    comparison_path = os.path.join(HYBRID_RESULTS_DIR, 'approach_comparison.json')\n",
    "    with open(comparison_path, 'w') as f:\n",
    "        json.dump(comparison, f, indent=4)\n",
    "\n",
    "    # Enhanced comparison plot\n",
    "    plot_metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    approaches = list(comparison.keys())\n",
    "\n",
    "    # High-quality colors for approaches (colorblind-friendly)\n",
    "    colors = ['#377eb8', '#ff7f00', '#4daf4a']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    x = np.arange(len(plot_metrics))\n",
    "    width = 0.25\n",
    "\n",
    "    # Plot bars for each approach with enhanced colors and edges\n",
    "    for i, (approach, color) in enumerate(zip(approaches, colors)):\n",
    "        values = [comparison[approach][m] for m in plot_metrics]\n",
    "        bars = ax.bar(x + i*width, values, width, label=approach,\n",
    "                     color=color, edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "        # Add value labels on top of bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # Add horizontal grid lines for better readability\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Customize axes\n",
    "    ax.set_ylabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax.set_title('Performance Comparison of Different Classification Approaches',\n",
    "                fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(metric_labels, fontweight='bold')\n",
    "\n",
    "    # Format y-axis as percentage\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "    # Set y-axis limits for better visualization\n",
    "    ax.set_ylim(0.7, 1.01)  # Start from 0.7 to better show differences\n",
    "\n",
    "    # Enhance legend\n",
    "    ax.legend(title='Approach', title_fontsize=14,\n",
    "              loc='lower left', fontsize=12, framealpha=0.9, edgecolor='black')\n",
    "\n",
    "    # Add annotations highlighting the best approach\n",
    "    best_approach = max(approaches, key=lambda x: comparison[x]['f1_score'])\n",
    "    best_f1 = comparison[best_approach]['f1_score']\n",
    "    ax.annotate(f'Best F1: {best_f1:.4f}',\n",
    "                xy=(3 + width, best_f1),  # Position at the F1 score bar\n",
    "                xytext=(3 + width, best_f1 + 0.05),  # Text position above bar\n",
    "                arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                fontsize=12, fontweight='bold', color='red',\n",
    "                ha='center')\n",
    "\n",
    "    # Improve overall appearance\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(HYBRID_PLOTS_DIR, 'approach_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Print comparison table\n",
    "    print(\"\\nPerformance Comparison Table:\")\n",
    "    print(f\"{'Approach':40} | {'Accuracy':10} | {'Precision':10} | {'Recall':10} | {'F1 Score':10}\")\n",
    "\n",
    "    for approach in approaches:\n",
    "        print(f\"{approach:40} | \"\n",
    "              f\"{comparison[approach]['accuracy']:.4f}     | \"\n",
    "              f\"{comparison[approach]['precision']:.4f}     | \"\n",
    "              f\"{comparison[approach]['recall']:.4f}     | \"\n",
    "              f\"{comparison[approach]['f1_score']:.4f}\")\n",
    "\n",
    "    # Determine best approach\n",
    "    best_approach = max(approaches, key=lambda x: comparison[x]['f1_score'])\n",
    "    print(f\"\\nBest Approach Based on F1 Score: {best_approach}\")\n",
    "    print(f\"F1 Score: {comparison[best_approach]['f1_score']:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Comparison with previous approaches not available.\")\n",
    "\n",
    "# Calculate total script execution time\n",
    "total_time_script = time.time() - start_time_script\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nHYBRID APPROACH COMPLETED\")\n",
    "print(f\"Best Model: {best_model_info['clf_name']}\")\n",
    "print(f\"F1 Score: {best_model_info['score']:.4f}\")\n",
    "print(f\"Accuracy: {best_model_info['results']['test_performance']['accuracy']:.4f}\")\n",
    "print(f\"Total execution time: {total_time_script/60:.1f} minutes\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID APPROACH: DEEP FEATURES + ML CLASSIFIERS\n",
      "STAGE 1: DEEP FEATURE EXTRACTION\n",
      "Total images to process: 5400\n",
      "DEEP FEATURE EXTRACTION COMPLETE\n",
      "Total samples: 5400 images\n",
      "Feature dimensionality: 384 features\n",
      "Processing time: 61.6 seconds (87.6 images/sec)\n",
      "STAGE 2: TRAIN ML CLASSIFIERS ON DEEP FEATURES\n",
      "★ SVM             | F1: 0.9478 | Acc: 0.9660 | Prec: 0.9727 | Rec: 0.9241\n",
      "★ RandomForest    | F1: 0.9532 | Acc: 0.9691 | Prec: 0.9640 | Rec: 0.9426\n",
      "  XGBoost         | F1: 0.9531 | Acc: 0.9691 | Prec: 0.9658 | Rec: 0.9407\n",
      "  ExtraTrees      | F1: 0.9522 | Acc: 0.9685 | Prec: 0.9639 | Rec: 0.9407\n",
      "  KNN             | F1: 0.9491 | Acc: 0.9667 | Prec: 0.9673 | Rec: 0.9315\n",
      "  DecisionTree    | F1: 0.9242 | Acc: 0.9488 | Prec: 0.9117 | Rec: 0.9370\n",
      "\n",
      "Performance Comparison Table:\n",
      "Approach                                 | Accuracy   | Precision  | Recall     | F1 Score  \n",
      "Pure ML\n",
      "(Handcrafted Features + SVM)     | 0.9117     | 0.9144     | 0.8111     | 0.8597\n",
      "Hybrid\n",
      "(Deep Features + ML)              | 0.9691     | 0.9640     | 0.9426     | 0.9532\n",
      "Pure DL\n",
      "(End-to-End Deep Learning)       | 0.9488     | 0.9705     | 0.8744     | 0.9200\n",
      "\n",
      "Best Approach Based on F1 Score: Hybrid\n",
      "(Deep Features + ML)\n",
      "F1 Score: 0.9532\n",
      "\n",
      "HYBRID APPROACH COMPLETED\n",
      "Best Model: RandomForest\n",
      "F1 Score: 0.9532\n",
      "Accuracy: 0.9691\n",
      "Total execution time: 5.5 minutes\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

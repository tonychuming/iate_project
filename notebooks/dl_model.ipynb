{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T20:58:51.207554Z",
     "start_time": "2025-03-30T09:21:11.754514Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "import time\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Advanced augmentation imports\n",
    "from torchvision.transforms import RandAugment\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    PSUTIL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PSUTIL_AVAILABLE = False\n",
    "\n",
    "# Global Config Variables\n",
    "BASE_PATH = Path(r\"D:\\iate_project\\data\")\n",
    "raw_dataset_path = BASE_PATH / \"raw\"\n",
    "output_path = BASE_PATH / \"results\"\n",
    "\n",
    "# Create output directories if necessary\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "os.makedirs(output_path / 'models', exist_ok=True)\n",
    "os.makedirs(output_path / 'results', exist_ok=True)\n",
    "os.makedirs(output_path / 'visualizations', exist_ok=True)\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # Windows compatibility\n",
    "NUM_EPOCHS = 10\n",
    "NUM_FOLDS = 5\n",
    "GRAD_CLIP_VALUE = 1.0\n",
    "\n",
    "USE_AMP = True  # Automatic Mixed Precision for faster training\n",
    "PIN_MEMORY = True\n",
    "DROP_RATE = 0.2  # Dropout rate for regularization\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 3  # Stop training if no improvement after this many epochs\n",
    "EARLY_STOPPING_MIN_DELTA = 0.0005  # Minimum change to qualify as improvement\n",
    "\n",
    "# Enable advanced augmentation techniques - these provide more robust training\n",
    "USE_ADVANCED_AUGMENTATION = True\n",
    "USE_MIXUP = True  # MixUp augmentation technique\n",
    "MIXUP_ALPHA = 0.2  # Alpha parameter for MixUp\n",
    "\n",
    "\"\"\"\n",
    "Model selection rationale:\n",
    "These lightweight models are specifically chosen for practical deployment in coffee industry settings:\n",
    "1. Edge device compatibility: Models need to run on low-power hardware in production environments\n",
    "2. Real-time inference: Coffee bean sorting requires fast processing (>10 beans/second)\n",
    "3. Memory efficiency: Limited RAM available on edge devices used in coffee processing facilities\n",
    "4. Energy consumption: Processing facilities may have power constraints\n",
    "5. Thermal considerations: Coffee processing environment may already be hot\n",
    "\n",
    "Effectiveness in image recognition tasks was balanced against these practical constraints.\n",
    "\"\"\"\n",
    "MODELS = {\n",
    "    # Very lightweight models for edge deployment\n",
    "    'mobilenetv3_small_100': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    },\n",
    "    'efficientnet_lite0': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    },\n",
    "    'mobilevit_xxs': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    },\n",
    "    'regnetx_002': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    },\n",
    "    # Slightly larger but still efficient models\n",
    "    'efficientnet_b0': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    },\n",
    "    'mobilevit_xs': {\n",
    "        'pretrained': True,\n",
    "        'lr': 5e-5,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Device Setup\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available! Using {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\"\"\"\n",
    "MixUp Augmentation Implementation\n",
    "This technique creates new training samples by linearly combining pairs of images and their labels,\n",
    "which has been shown to improve model generalization and robustness.\n",
    "\"\"\"\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    '''Calculates the mixed loss'''\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Dataset class with advanced augmentation strategies\n",
    "class CoffeeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for loading coffee bean images with enhanced augmentation strategies.\n",
    "\n",
    "    Coffee bean images are collected with varying conditions including:\n",
    "    - Processing methods (dry, honey, wet)\n",
    "    - Roast levels (dark, light, medium)\n",
    "    - Bean condition (normal, defect)\n",
    "\n",
    "    Advanced augmentation helps the model generalize across these variations.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split='train', test_ratio=0.15, val_ratio=0.15):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.samples = []\n",
    "        self.max_retries = 3\n",
    "\n",
    "        # Load all samples from the specified directory structure\n",
    "        normal_path = os.path.join(self.root_dir, \"Normal\")\n",
    "        defect_path = os.path.join(self.root_dir, \"Defect\")\n",
    "\n",
    "        # Handle case sensitivity\n",
    "        if not os.path.exists(normal_path):\n",
    "            normal_path = os.path.join(self.root_dir, \"normal\")\n",
    "        if not os.path.exists(defect_path):\n",
    "            defect_path = os.path.join(self.root_dir, \"defect\")\n",
    "\n",
    "        print(f\"Loading samples from Normal: {normal_path}\")\n",
    "        print(f\"Loading samples from Defect: {defect_path}\")\n",
    "\n",
    "        # Process methods (Dry, Honey, Wet)\n",
    "        all_filepaths = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Process Normal samples\n",
    "        for method in ['Dry', 'Honey', 'Wet', 'dry', 'honey', 'wet']:\n",
    "            method_path = os.path.join(normal_path, method)\n",
    "            if not os.path.exists(method_path):\n",
    "                continue\n",
    "\n",
    "            for roast in ['Dark', 'Light', 'Medium', 'dark', 'light', 'medium']:\n",
    "                roast_path = os.path.join(method_path, roast)\n",
    "                if not os.path.exists(roast_path):\n",
    "                    continue\n",
    "\n",
    "                for img_name in os.listdir(roast_path):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        all_filepaths.append(os.path.join(roast_path, img_name))\n",
    "                        all_labels.append(0)  # Normal\n",
    "\n",
    "        # Process Defect samples\n",
    "        for method in ['Dry', 'Honey', 'Wet', 'dry', 'honey', 'wet']:\n",
    "            method_path = os.path.join(defect_path, method)\n",
    "            if not os.path.exists(method_path):\n",
    "                continue\n",
    "\n",
    "            for roast in ['Dark', 'Light', 'Medium', 'dark', 'light', 'medium']:\n",
    "                roast_path = os.path.join(method_path, roast)\n",
    "                if not os.path.exists(roast_path):\n",
    "                    continue\n",
    "\n",
    "                for img_name in os.listdir(roast_path):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        all_filepaths.append(os.path.join(roast_path, img_name))\n",
    "                        all_labels.append(1)  # Defect\n",
    "\n",
    "        # Split the dataset into train, validation, and test sets\n",
    "        unique_paths = list(set(all_filepaths))  # Ensure no duplicates\n",
    "        random.shuffle(unique_paths)\n",
    "\n",
    "        test_size = int(len(unique_paths) * test_ratio)\n",
    "        val_size = int(len(unique_paths) * val_ratio)\n",
    "\n",
    "        test_paths = set(unique_paths[:test_size])\n",
    "        val_paths = set(unique_paths[test_size:test_size + val_size])\n",
    "        train_paths = set(unique_paths[test_size + val_size:])\n",
    "\n",
    "        # Assign samples based on split\n",
    "        if split == 'train':\n",
    "            target_paths = train_paths\n",
    "        elif split == 'val':\n",
    "            target_paths = val_paths\n",
    "        else:  # 'test'\n",
    "            target_paths = test_paths\n",
    "\n",
    "        # Filter samples for the current split\n",
    "        for filepath, label in zip(all_filepaths, all_labels):\n",
    "            if filepath in target_paths:\n",
    "                self.samples.append({\n",
    "                    'filepath': filepath,\n",
    "                    'label': label\n",
    "                })\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} samples for split: {self.split}\")\n",
    "\n",
    "        # Analyze class distribution\n",
    "        labels = [sample['label'] for sample in self.samples]\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "\n",
    "        print(f\"\\n{self.split} set class distribution:\")\n",
    "        for label, count in class_counts.items():\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"Class {label}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "        # Configure transformations based on dataset split\n",
    "        if self.split == 'train':\n",
    "            if USE_ADVANCED_AUGMENTATION:\n",
    "                # Advanced augmentation pipeline for more robust training\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.RandomVerticalFlip(p=0.3),\n",
    "                    transforms.RandomRotation(\n",
    "                        degrees=30,\n",
    "                        fill=1.0,\n",
    "                        interpolation=transforms.InterpolationMode.BILINEAR\n",
    "                    ),\n",
    "                    # Add RandAugment for automated augmentation policy\n",
    "                    RandAugment(num_ops=2, magnitude=9),\n",
    "                    # Color jitter specifically tuned for coffee beans\n",
    "                    transforms.ColorJitter(\n",
    "                        brightness=0.3, contrast=0.3,\n",
    "                        saturation=0.3, hue=0.1\n",
    "                    ),\n",
    "                    # Add random perspective for 3D-like variations\n",
    "                    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "                    # Add occasional grayscale conversion to focus on texture\n",
    "                    transforms.RandomGrayscale(p=0.1),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "            else:\n",
    "                # Standard augmentation pipeline\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.RandomVerticalFlip(p=0.3),\n",
    "                    transforms.RandomRotation(\n",
    "                        degrees=30,\n",
    "                        fill=1.0,\n",
    "                        interpolation=transforms.InterpolationMode.BILINEAR\n",
    "                    ),\n",
    "                    transforms.ColorJitter(\n",
    "                        brightness=0.2, contrast=0.2,\n",
    "                        saturation=0.2, hue=0.1\n",
    "                    ),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        else:\n",
    "            # Validation and test transforms - keep simple for efficiency\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        image_path = sample['filepath']\n",
    "        label = sample['label']\n",
    "\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                return self.transform(image), label\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load/transform image {image_path} on attempt {attempt+1}: {str(e)}\")\n",
    "                idx = (idx + 1) % len(self)\n",
    "\n",
    "        print(f\"Failed to load image {image_path} after {self.max_retries} attempts. Returning default sample.\")\n",
    "        return torch.zeros(3, 224, 224), -1\n",
    "\n",
    "# Create Datasets\n",
    "print(\"Creating train/val/test datasets...\")\n",
    "\n",
    "# Create separate instances for train, val, test\n",
    "train_dataset = CoffeeDataset(str(raw_dataset_path), split='train')\n",
    "val_dataset = CoffeeDataset(str(raw_dataset_path), split='val')\n",
    "test_dataset = CoffeeDataset(str(raw_dataset_path), split='test')\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# Initialize model tracking variables\n",
    "print(\"Initializing models for evaluation...\")\n",
    "models_info = {}\n",
    "all_training_results = {}\n",
    "all_test_results = {}\n",
    "\n",
    "\"\"\"\n",
    "K-fold Cross-Validation Strategy:\n",
    "\n",
    "This implementation uses K-fold CV with a specific purpose different from typical hyperparameter tuning:\n",
    "1. For each model architecture, we train multiple versions with different data splits\n",
    "2. We select the best performing model checkpoint based on validation performance\n",
    "3. This approach helps overcome potential bias from any single train/val split\n",
    "4. The final selected model is evaluated on a completely separate test set\n",
    "\n",
    "Why this approach versus traditional CV for hyperparameter tuning:\n",
    "- In low-data regimes and with class imbalance, performance can vary significantly based on the specific data split\n",
    "- This helps us identify the most robust model for real-world deployment\n",
    "- The test set remains untouched during this process, maintaining proper evaluation protocol\n",
    "\"\"\"\n",
    "\n",
    "# Iterate through all models to train and evaluate\n",
    "for model_name, model_cfg in MODELS.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Starting process for model: {model_name}\")\n",
    "\n",
    "    try:\n",
    "        # Create the model\n",
    "        model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=model_cfg['pretrained'],\n",
    "            num_classes=2,\n",
    "            drop_rate=DROP_RATE\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Calculate model parameters and size\n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "        # Calculate model size in MB\n",
    "        param_size = 0\n",
    "        for param in model.parameters():\n",
    "            param_size += param.nelement() * param.element_size()\n",
    "        buffer_size = 0\n",
    "        for buffer in model.buffers():\n",
    "            buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        size_mb = (param_size + buffer_size) / 1024**2\n",
    "\n",
    "        # Store model information\n",
    "        models_info[model_name] = {\n",
    "            'model': model,\n",
    "            'lr': model_cfg['lr'],\n",
    "            'size_mb': size_mb,\n",
    "            'param_count': param_count\n",
    "        }\n",
    "\n",
    "        print(f\"Initialized model: {model_name}\")\n",
    "        print(f\"  - Parameters: {param_count:,}\")\n",
    "        print(f\"  - Size: {size_mb:.2f} MB\")\n",
    "\n",
    "        # Prepare for K-Fold cross-validation\n",
    "        print(f\"\\nStarting K-Fold cross-validation for model: {model_name}\")\n",
    "        start_time = time.time()\n",
    "        current_fold_metrics = []\n",
    "        best_global_state = None\n",
    "        best_global_loss = float('inf')\n",
    "        best_global_fold = None\n",
    "\n",
    "        # Get labels for stratified sampling\n",
    "        labels_train_dataset = [sample['label'] for sample in train_dataset.samples]\n",
    "        kf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "        # Loop through each fold\n",
    "        for fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset.samples, labels_train_dataset), 1):\n",
    "            print(f\"\\nStarting fold {fold}/{NUM_FOLDS}\")\n",
    "\n",
    "            # Create subset for train/val\n",
    "            train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "            val_subset = torch.utils.data.Subset(train_dataset, val_indices)\n",
    "\n",
    "            # Re-init model for each fold\n",
    "            fold_model = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=True,\n",
    "                num_classes=2,\n",
    "                drop_rate=DROP_RATE\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            # Set up optimizer\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                fold_model.parameters(),\n",
    "                lr=model_cfg['lr'],\n",
    "                weight_decay=0.01,\n",
    "                betas=(0.9, 0.999)\n",
    "            )\n",
    "\n",
    "            # Set up learning rate scheduler\n",
    "            scheduler = CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=NUM_EPOCHS,\n",
    "                eta_min=1e-6\n",
    "            )\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            scaler = GradScaler(enabled=USE_AMP)\n",
    "\n",
    "            # Create DataLoader for subset\n",
    "            fold_train_loader = DataLoader(\n",
    "                train_subset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=PIN_MEMORY,\n",
    "                drop_last=True\n",
    "            )\n",
    "\n",
    "            fold_val_loader = DataLoader(\n",
    "                val_subset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=PIN_MEMORY\n",
    "            )\n",
    "\n",
    "            # Prepare training history\n",
    "            training_history = {\n",
    "                'train_loss': [], 'val_loss': [],\n",
    "                'train_acc': [], 'val_acc': [],\n",
    "                'train_metrics': [], 'val_metrics': [],\n",
    "                'lr_history': [], 'epoch_times': []\n",
    "            }\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            best_model_state = None\n",
    "\n",
    "            # Early stopping state\n",
    "            es_best_loss = None\n",
    "            es_counter = 0\n",
    "            es_early_stop = False\n",
    "\n",
    "            # Start epoch loop\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                epoch_start_time = time.time()\n",
    "\n",
    "                # -------------------- TRAIN EPOCH --------------------\n",
    "                fold_model.train()\n",
    "                running_loss = 0.0\n",
    "                predictions = []\n",
    "                targets_list = []\n",
    "                probabilities_list = []\n",
    "\n",
    "                for images, labels in fold_train_loader:\n",
    "                    images = images.to(DEVICE, non_blocking=True)\n",
    "                    labels = labels.to(DEVICE, non_blocking=True)\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                    # Apply MixUp augmentation if enabled\n",
    "                    if USE_MIXUP and np.random.random() < 0.5:\n",
    "                        mixed_images, labels_a, labels_b, lam = mixup_data(images, labels, MIXUP_ALPHA)\n",
    "\n",
    "                        with autocast(device_type='cuda', enabled=USE_AMP):\n",
    "                            outputs = fold_model(mixed_images)\n",
    "                            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                    else:\n",
    "                        with autocast(device_type='cuda', enabled=USE_AMP):\n",
    "                            outputs = fold_model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "                    if USE_AMP:\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(fold_model.parameters(), GRAD_CLIP_VALUE)\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(fold_model.parameters(), GRAD_CLIP_VALUE)\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * images.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    predictions.extend(preds.detach().cpu().numpy())\n",
    "                    probabilities_list.extend(probs.detach().cpu().numpy())\n",
    "                    targets_list.extend(labels.cpu().numpy())\n",
    "\n",
    "                epoch_train_loss = running_loss / len(fold_train_loader.dataset)\n",
    "\n",
    "                # Calculate training metrics\n",
    "                train_metrics = {}\n",
    "                train_metrics['loss'] = epoch_train_loss\n",
    "\n",
    "                # Calculate accuracy\n",
    "                train_metrics['accuracy'] = accuracy_score(targets_list, predictions)\n",
    "                train_metrics['precision'] = precision_score(targets_list, predictions, average='binary', zero_division=0)\n",
    "                train_metrics['recall'] = recall_score(targets_list, predictions, average='binary', zero_division=0)\n",
    "                train_metrics['f1_score'] = f1_score(targets_list, predictions, average='binary', zero_division=0)\n",
    "\n",
    "                # Try to calculate ROC-AUC if possible\n",
    "                try:\n",
    "                    train_metrics['roc_auc'] = roc_auc_score(targets_list, probabilities_list)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ROC-AUC calculation failed: {str(e)}\")\n",
    "                    train_metrics['roc_auc'] = 0.0\n",
    "\n",
    "                # -------------------- VALIDATE EPOCH --------------------\n",
    "                fold_model.eval()\n",
    "                val_running_loss = 0.0\n",
    "                val_predictions = []\n",
    "                val_targets_list = []\n",
    "                val_probabilities_list = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for images_val, labels_val in fold_val_loader:\n",
    "                        images_val = images_val.to(DEVICE, non_blocking=True)\n",
    "                        labels_val = labels_val.to(DEVICE, non_blocking=True)\n",
    "                        outputs_val = fold_model(images_val)\n",
    "                        loss_val = criterion(outputs_val, labels_val)\n",
    "                        probs_val = torch.softmax(outputs_val, dim=1)[:, 1]\n",
    "\n",
    "                        val_running_loss += loss_val.item() * images_val.size(0)\n",
    "                        _, preds_val = torch.max(outputs_val, 1)\n",
    "                        val_predictions.extend(preds_val.detach().cpu().numpy())\n",
    "                        val_probabilities_list.extend(probs_val.detach().cpu().numpy())\n",
    "                        val_targets_list.extend(labels_val.cpu().numpy())\n",
    "\n",
    "                val_loss = val_running_loss / len(fold_val_loader.dataset)\n",
    "\n",
    "                # Calculate validation metrics\n",
    "                val_metrics = {}\n",
    "                val_metrics['loss'] = val_loss\n",
    "                val_metrics['accuracy'] = accuracy_score(val_targets_list, val_predictions)\n",
    "                val_metrics['precision'] = precision_score(val_targets_list, val_predictions, average='binary', zero_division=0)\n",
    "                val_metrics['recall'] = recall_score(val_targets_list, val_predictions, average='binary', zero_division=0)\n",
    "                val_metrics['f1_score'] = f1_score(val_targets_list, val_predictions, average='binary', zero_division=0)\n",
    "\n",
    "                # Try to calculate ROC-AUC if possible\n",
    "                try:\n",
    "                    val_metrics['roc_auc'] = roc_auc_score(val_targets_list, val_probabilities_list)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ROC-AUC calculation failed: {str(e)}\")\n",
    "                    val_metrics['roc_auc'] = 0.0\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                cm = confusion_matrix(val_targets_list, val_predictions)\n",
    "                if cm.shape == (2, 2):\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    val_metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                    val_metrics['confusion_matrix'] = cm.tolist()\n",
    "\n",
    "                # Logging training/val info\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "                      f\"Train Loss: {train_metrics['loss']:.4f} | \"\n",
    "                      f\"Val Loss: {val_metrics['loss']:.4f} | \"\n",
    "                      f\"Val F1: {val_metrics['f1_score']:.4f} | \"\n",
    "                      f\"Val Acc: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "                # Log GPU stats\n",
    "                if torch.cuda.is_available():\n",
    "                    memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "                    memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "                    print(f\"GPU Memory: Allocated {memory_allocated:.1f}MB, Reserved {memory_reserved:.1f}MB\")\n",
    "\n",
    "                # Step the scheduler\n",
    "                scheduler.step()\n",
    "\n",
    "                # Update training history\n",
    "                training_history['train_loss'].append(train_metrics['loss'])\n",
    "                training_history['val_loss'].append(val_metrics['loss'])\n",
    "                training_history['train_acc'].append(train_metrics['accuracy'])\n",
    "                training_history['val_acc'].append(val_metrics['accuracy'])\n",
    "                training_history['train_metrics'].append(train_metrics)\n",
    "                training_history['val_metrics'].append(val_metrics)\n",
    "                training_history['lr_history'].append(current_lr)\n",
    "                training_history['epoch_times'].append(time.time() - epoch_start_time)\n",
    "\n",
    "                # Save best model for this fold\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = fold_model.state_dict().copy()\n",
    "\n",
    "                # Check for early stopping\n",
    "                if es_best_loss is None:\n",
    "                    es_best_loss = val_loss\n",
    "                else:\n",
    "                    if val_loss > es_best_loss - EARLY_STOPPING_MIN_DELTA:\n",
    "                        es_counter += 1\n",
    "                        if es_counter >= EARLY_STOPPING_PATIENCE:\n",
    "                            print(\"Early stopping triggered.\")\n",
    "                            break\n",
    "                    else:\n",
    "                        es_best_loss = val_loss\n",
    "                        es_counter = 0\n",
    "\n",
    "                # Optional performance threshold for early termination\n",
    "                if val_metrics['f1_score'] > 0.95:\n",
    "                    print(f\"Achieved target F1 score: {val_metrics['f1_score']:.4f}. Stopping early.\")\n",
    "                    break\n",
    "\n",
    "            # After finishing epochs for this fold\n",
    "            if best_model_state is not None:\n",
    "                fold_model.load_state_dict(best_model_state)\n",
    "\n",
    "            # Summarize fold results\n",
    "            final_train_metrics = training_history['train_metrics'][-1]\n",
    "            final_val_metrics = training_history['val_metrics'][-1]\n",
    "\n",
    "            print(f\"\\nFold {fold} Summary - {model_name}:\")\n",
    "            print(f\"Validation Metrics:\")\n",
    "            print(f\"- Accuracy: {final_val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"- F1 Score: {final_val_metrics['f1_score']:.4f}\")\n",
    "            print(f\"- Precision: {final_val_metrics['precision']:.4f}\")\n",
    "            print(f\"- Recall: {final_val_metrics['recall']:.4f}\")\n",
    "\n",
    "            current_fold_metrics.append(training_history)\n",
    "\n",
    "            # Check if this fold is better globally\n",
    "            if best_val_loss < best_global_loss:\n",
    "                best_global_loss = best_val_loss\n",
    "                best_global_state = best_model_state\n",
    "                best_global_fold = fold\n",
    "\n",
    "            # Plot training curves for this fold\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(training_history['train_loss'], label='Training Loss')\n",
    "            plt.plot(training_history['val_loss'], label='Validation Loss')\n",
    "            plt.title('Loss Curves')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(training_history['train_acc'], label='Training Accuracy')\n",
    "            plt.plot(training_history['val_acc'], label='Validation Accuracy')\n",
    "            plt.title('Accuracy Curves')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(training_history['lr_history'], label='Learning Rate')\n",
    "            plt.title('Learning Rate Schedule')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.yscale('log')\n",
    "\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.plot(training_history['epoch_times'], label='Training Time')\n",
    "            plt.title('Training Time per Epoch')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Time (seconds)')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(str(output_path), 'visualizations', f\"{model_name}_fold{fold}_training_curves.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # Clean up\n",
    "            del train_subset, val_subset, fold_train_loader, fold_val_loader, optimizer, criterion, fold_model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        # After all folds, recreate the model and load best weights\n",
    "        best_model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=2,\n",
    "            drop_rate=DROP_RATE\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        if best_global_state is not None:\n",
    "            best_model.load_state_dict(best_global_state)\n",
    "            print(f\"Loaded best fold state (fold {best_global_fold}) for {model_name}.\")\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        training_result = {\n",
    "            'model': best_model,\n",
    "            'all_fold_metrics': current_fold_metrics,\n",
    "            'training_time': training_time,\n",
    "            'best_fold': best_global_fold\n",
    "        }\n",
    "\n",
    "        all_training_results[model_name] = training_result\n",
    "\n",
    "        # Now evaluate this model on the test set\n",
    "        print(f\"Evaluating {model_name} on test set...\")\n",
    "        criterion_test = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Evaluation block\n",
    "        best_model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_predictions = []\n",
    "        test_targets = []\n",
    "        test_probabilities = []\n",
    "        test_inference_times = []\n",
    "        test_batch_sizes = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                test_batch_sizes.append(images.shape[0])\n",
    "                images = images.to(DEVICE, non_blocking=True)\n",
    "                labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "                # Warm-up run to eliminate first-batch overhead\n",
    "                if len(test_inference_times) == 0:\n",
    "                    _ = best_model(images)\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.synchronize()\n",
    "\n",
    "                # Measure inference time\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.synchronize()\n",
    "                start_time = time.time()\n",
    "                outputs = best_model(images)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.synchronize()\n",
    "                inference_time = time.time() - start_time\n",
    "                test_inference_times.append(inference_time)\n",
    "\n",
    "                loss = criterion_test(outputs, labels)\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "                test_running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                test_predictions.extend(preds.cpu().numpy())\n",
    "                test_targets.extend(labels.cpu().numpy())\n",
    "                test_probabilities.extend(probs.cpu().numpy())\n",
    "\n",
    "        # Compute test metrics\n",
    "        test_loss = test_running_loss / len(test_loader.dataset)\n",
    "\n",
    "        # Calculate metrics\n",
    "        test_metrics = {}\n",
    "        test_metrics['loss'] = test_loss\n",
    "        test_metrics['accuracy'] = accuracy_score(test_targets, test_predictions)\n",
    "        test_metrics['precision'] = precision_score(test_targets, test_predictions, average='binary', zero_division=0)\n",
    "        test_metrics['recall'] = recall_score(test_targets, test_predictions, average='binary', zero_division=0)\n",
    "        test_metrics['f1_score'] = f1_score(test_targets, test_predictions, average='binary', zero_division=0)\n",
    "\n",
    "        # Try to calculate ROC-AUC if possible\n",
    "        try:\n",
    "            test_metrics['roc_auc'] = roc_auc_score(test_targets, test_probabilities)\n",
    "        except ValueError as e:\n",
    "            print(f\"ROC-AUC calculation failed: {str(e)}\")\n",
    "            test_metrics['roc_auc'] = 0.0\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(test_targets, test_predictions)\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            test_metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            test_metrics['confusion_matrix'] = cm.tolist()\n",
    "\n",
    "        # Print classification report\n",
    "        report_text = classification_report(\n",
    "            test_targets,\n",
    "            test_predictions,\n",
    "            target_names=['Normal', 'Defect'],\n",
    "            digits=4\n",
    "        )\n",
    "        print(f\"\\nDetailed Classification Report:\\n{report_text}\")\n",
    "\n",
    "        # Inference time calculations\n",
    "        total_samples = sum(test_batch_sizes)\n",
    "        total_inference_time = sum(test_inference_times)\n",
    "\n",
    "        # Skip the first batch timing (warm-up)\n",
    "        if len(test_inference_times) > 1:\n",
    "            avg_inference_time = sum(test_inference_times[1:]) / (len(test_inference_times) - 1)\n",
    "            inference_time_per_image = sum(test_inference_times[1:]) / sum(test_batch_sizes[1:])\n",
    "        else:\n",
    "            avg_inference_time = total_inference_time\n",
    "            inference_time_per_image = total_inference_time / total_samples\n",
    "\n",
    "        test_metrics['avg_inference_time'] = avg_inference_time  # Average time per batch\n",
    "        test_metrics['inference_time_per_image'] = inference_time_per_image  # Average time per image\n",
    "        test_metrics['total_inference_time'] = total_inference_time\n",
    "        test_metrics['images_per_second'] = 1.0 / inference_time_per_image if inference_time_per_image > 0 else 0\n",
    "\n",
    "        # Save test results\n",
    "        test_results_dir = os.path.join(str(output_path), 'results')\n",
    "        os.makedirs(test_results_dir, exist_ok=True)\n",
    "\n",
    "        # Store test results\n",
    "        all_test_results[model_name] = {\n",
    "            'metrics': test_metrics,\n",
    "            'targets': test_targets,\n",
    "            'predictions': test_predictions,\n",
    "            'probabilities': test_probabilities\n",
    "        }\n",
    "\n",
    "        # Save results to file\n",
    "        test_results_path = os.path.join(test_results_dir, f\"{model_name}_test_results.json\")\n",
    "        test_data_dict = {\n",
    "            \"targets\": [int(t) for t in test_targets],\n",
    "            \"predictions\": [int(p) for p in test_predictions],\n",
    "            \"probabilities\": [float(prob) for prob in test_probabilities],\n",
    "            \"metrics\": {k: float(v) if isinstance(v, (int, float)) else v\n",
    "                      for k, v in test_metrics.items() if k != 'confusion_matrix'}\n",
    "        }\n",
    "\n",
    "        with open(test_results_path, 'w') as f_out:\n",
    "            json.dump(test_data_dict, f_out, indent=4)\n",
    "\n",
    "        # Confusion matrix plot\n",
    "        if 'confusion_matrix' in test_metrics:\n",
    "            cm_array = np.array(test_metrics['confusion_matrix'])\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm_array, annot=True, fmt='d', cmap='Blues',\n",
    "                      xticklabels=['Normal', 'Defect'],\n",
    "                      yticklabels=['Normal', 'Defect'])\n",
    "            plt.title(f'Confusion Matrix - {model_name}')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.savefig(os.path.join(str(output_path), 'visualizations', f\"{model_name}_test_confusion_matrix.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # Save the final model\n",
    "        model_save_path = os.path.join(str(output_path), 'models', f\"{model_name}_final_model.pth\")\n",
    "        torch.save(best_model.state_dict(), model_save_path)\n",
    "        print(f\"Saved final model to {model_save_path}\")\n",
    "\n",
    "        # Print detailed metrics\n",
    "        print(f\"Test Results for {model_name}:\")\n",
    "        print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "        print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "        print(f\"  ROC-AUC: {test_metrics.get('roc_auc', 'N/A')}\")\n",
    "        print(f\"  Inference Speed: {test_metrics['images_per_second']:.2f} images/second\")\n",
    "\n",
    "        # Clean up\n",
    "        del best_model, criterion_test\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Select best model based on test results\n",
    "print(\"\\nSelecting best final model...\")\n",
    "\n",
    "best_final_model = None\n",
    "best_final_score = -float('inf')\n",
    "\n",
    "for model_name, result in all_test_results.items():\n",
    "    metrics = result['metrics']\n",
    "\n",
    "    # Calculate balanced score for final selection\n",
    "    # Balance accuracy, F1 score, and efficiency\n",
    "    accuracy = metrics['accuracy']\n",
    "    f1_score_val = metrics['f1_score']\n",
    "    inference_speed = metrics['images_per_second']\n",
    "    model_size = models_info[model_name]['size_mb']\n",
    "\n",
    "    # Score formula: 40% F1, 30% accuracy, 20% speed, 10% size efficiency\n",
    "    # This balances model performance with practical deployment considerations\n",
    "    final_score = (0.4 * f1_score_val +                         # Performance: F1 score\n",
    "                  0.3 * accuracy +                              # Performance: Accuracy\n",
    "                  0.2 * min(1.0, inference_speed / 100) +      # Efficiency: Speed\n",
    "                  0.1 * (1.0 - min(1.0, model_size / 100)))    # Efficiency: Size\n",
    "\n",
    "    print(f\"{model_name} final score: {final_score:.4f}\")\n",
    "\n",
    "    if final_score > best_final_score:\n",
    "        best_final_score = final_score\n",
    "        best_final_model = model_name\n",
    "\n",
    "# Save comprehensive results\n",
    "final_comparison = {\n",
    "    'models': {},\n",
    "    'best_model': best_final_model,\n",
    "    'training_time': {model: result['training_time'] for model, result in all_training_results.items()}\n",
    "}\n",
    "\n",
    "for model_name in models_info:\n",
    "    if model_name in all_test_results:\n",
    "        test_metrics = all_test_results[model_name]['metrics']\n",
    "        model_size = models_info[model_name]['size_mb']\n",
    "        param_count = models_info[model_name]['param_count']\n",
    "\n",
    "        final_comparison['models'][model_name] = {\n",
    "            'accuracy': test_metrics['accuracy'],\n",
    "            'f1_score': test_metrics['f1_score'],\n",
    "            'precision': test_metrics['precision'],\n",
    "            'recall': test_metrics['recall'],\n",
    "            'roc_auc': test_metrics.get('roc_auc', 0),\n",
    "            'size_mb': model_size,\n",
    "            'param_count': param_count,\n",
    "            'inference_time_ms': test_metrics['inference_time_per_image'] * 1000,\n",
    "            'images_per_second': test_metrics['images_per_second']\n",
    "        }\n",
    "\n",
    "# Save final comparison\n",
    "comparison_path = os.path.join(str(output_path), 'results', 'final_model_comparison.json')\n",
    "with open(comparison_path, 'w') as f:\n",
    "    json.dump(final_comparison, f, indent=4)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "if best_final_model:\n",
    "    print(f\"Best model: {best_final_model}\")\n",
    "    print(f\"  - Size: {models_info[best_final_model]['size_mb']:.2f} MB\")\n",
    "    print(f\"  - Parameters: {models_info[best_final_model]['param_count']:,}\")\n",
    "    print(f\"  - Accuracy: {all_test_results[best_final_model]['metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  - F1 Score: {all_test_results[best_final_model]['metrics']['f1_score']:.4f}\")\n",
    "    print(f\"  - Inference: {all_test_results[best_final_model]['metrics']['images_per_second']:.2f} img/sec\")\n",
    "\n",
    "    # Create summary report file\n",
    "    with open(os.path.join(str(output_path), 'best_model_summary.txt'), 'w') as f:\n",
    "        f.write(\"=== COFFEE BEAN DEFECT DETECTION - BEST MODEL SUMMARY ===\\n\\n\")\n",
    "        f.write(f\"Best Model: {best_final_model}\\n\")\n",
    "        f.write(f\"Model Size: {models_info[best_final_model]['size_mb']:.2f} MB\\n\")\n",
    "        f.write(f\"Parameters: {models_info[best_final_model]['param_count']:,}\\n\")\n",
    "        f.write(f\"Accuracy: {all_test_results[best_final_model]['metrics']['accuracy']:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {all_test_results[best_final_model]['metrics']['f1_score']:.4f}\\n\")\n",
    "        f.write(f\"Precision: {all_test_results[best_final_model]['metrics']['precision']:.4f}\\n\")\n",
    "        f.write(f\"Recall: {all_test_results[best_final_model]['metrics']['recall']:.4f}\\n\")\n",
    "        f.write(f\"Inference Time: {all_test_results[best_final_model]['metrics']['inference_time_per_image']*1000:.2f} ms/image\\n\")\n",
    "        f.write(f\"Processing Speed: {all_test_results[best_final_model]['metrics']['images_per_second']:.2f} images/second\\n\\n\")\n",
    "        f.write(\"=== Model Comparison ===\\n\")\n",
    "\n",
    "        for model_name in models_info:\n",
    "            if model_name in all_test_results:\n",
    "                metrics = all_test_results[model_name]['metrics']\n",
    "                f.write(f\"{model_name}:\\n\")\n",
    "                f.write(f\"  - Size: {models_info[model_name]['size_mb']:.2f} MB\\n\")\n",
    "                f.write(f\"  - F1 Score: {metrics['f1_score']:.4f}\\n\")\n",
    "                f.write(f\"  - Speed: {metrics['images_per_second']:.2f} img/sec\\n\\n\")\n",
    "else:\n",
    "    print(\"No models were successfully trained and evaluated.\")\n",
    "\n",
    "print(\"Training pipeline completed successfully!\")\n",
    "\n",
    "# Final cleanup\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Cleanup done.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA Version: 12.6\n",
      "Creating train/val/test datasets...\n",
      "Loading samples from Normal: D:\\iate_project\\original_dataset\\Normal\n",
      "Loading samples from Defect: D:\\iate_project\\original_dataset\\Defect\n",
      "Loaded 15120 samples for split: train\n",
      "\n",
      "train set class distribution:\n",
      "Class 0: 10121 samples (66.94%)\n",
      "Class 1: 4999 samples (33.06%)\n",
      "Loading samples from Normal: D:\\iate_project\\original_dataset\\Normal\n",
      "Loading samples from Defect: D:\\iate_project\\original_dataset\\Defect\n",
      "Loaded 3240 samples for split: val\n",
      "\n",
      "val set class distribution:\n",
      "Class 0: 2126 samples (65.62%)\n",
      "Class 1: 1114 samples (34.38%)\n",
      "Loading samples from Normal: D:\\iate_project\\original_dataset\\Normal\n",
      "Loading samples from Defect: D:\\iate_project\\original_dataset\\Defect\n",
      "Loaded 3240 samples for split: test\n",
      "\n",
      "test set class distribution:\n",
      "Class 0: 2149 samples (66.33%)\n",
      "Class 1: 1091 samples (33.67%)\n",
      "Dataset sizes:\n",
      "Train: 15120 samples\n",
      "Validation: 3240 samples\n",
      "Test: 3240 samples\n",
      "Initializing models for evaluation...\n",
      "\n",
      "==================================================\n",
      "Starting process for model: mobilenetv3_small_100\n",
      "Initialized model: mobilenetv3_small_100\n",
      "  - Parameters: 1,519,906\n",
      "  - Size: 5.84 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: mobilenetv3_small_100\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 1.3262 | Val Loss: 0.5954 | Val F1: 0.7040 | Val Acc: 0.8022\n",
      "GPU Memory: Allocated 92.5MB, Reserved 154.0MB\n",
      "Epoch 2/10 | Train Loss: 0.7377 | Val Loss: 0.4167 | Val F1: 0.7538 | Val Acc: 0.8562\n",
      "GPU Memory: Allocated 92.5MB, Reserved 508.0MB\n",
      "Epoch 3/10 | Train Loss: 0.6104 | Val Loss: 0.3510 | Val F1: 0.7854 | Val Acc: 0.8737\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 4/10 | Train Loss: 0.5363 | Val Loss: 0.4066 | Val F1: 0.7488 | Val Acc: 0.8657\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4613 | Val Loss: 0.2782 | Val F1: 0.8237 | Val Acc: 0.8978\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 6/10 | Train Loss: 0.4158 | Val Loss: 0.2371 | Val F1: 0.8494 | Val Acc: 0.9005\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3768 | Val Loss: 0.2196 | Val F1: 0.8628 | Val Acc: 0.9157\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3457 | Val Loss: 0.1979 | Val F1: 0.8730 | Val Acc: 0.9200\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3473 | Val Loss: 0.2472 | Val F1: 0.8509 | Val Acc: 0.9124\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3369 | Val Loss: 0.2016 | Val F1: 0.8738 | Val Acc: 0.9229\n",
      "GPU Memory: Allocated 92.0MB, Reserved 508.0MB\n",
      "\n",
      "Fold 1 Summary - mobilenetv3_small_100:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9229\n",
      "- F1 Score: 0.8738\n",
      "- Precision: 0.9517\n",
      "- Recall: 0.8078\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 1.4315 | Val Loss: 0.6276 | Val F1: 0.6818 | Val Acc: 0.8056\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 2/10 | Train Loss: 0.7382 | Val Loss: 0.4691 | Val F1: 0.7418 | Val Acc: 0.8158\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 3/10 | Train Loss: 0.6467 | Val Loss: 0.3012 | Val F1: 0.8186 | Val Acc: 0.8800\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 4/10 | Train Loss: 0.5464 | Val Loss: 0.3194 | Val F1: 0.7866 | Val Acc: 0.8780\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4412 | Val Loss: 0.2415 | Val F1: 0.8527 | Val Acc: 0.9031\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3944 | Val Loss: 0.2535 | Val F1: 0.8438 | Val Acc: 0.9061\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3886 | Val Loss: 0.2261 | Val F1: 0.8609 | Val Acc: 0.9150\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3625 | Val Loss: 0.1947 | Val F1: 0.8720 | Val Acc: 0.9213\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3451 | Val Loss: 0.2063 | Val F1: 0.8707 | Val Acc: 0.9213\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3493 | Val Loss: 0.2018 | Val F1: 0.8754 | Val Acc: 0.9233\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "\n",
      "Fold 2 Summary - mobilenetv3_small_100:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9233\n",
      "- F1 Score: 0.8754\n",
      "- Precision: 0.9455\n",
      "- Recall: 0.8150\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 1.3728 | Val Loss: 0.5636 | Val F1: 0.6760 | Val Acc: 0.8095\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 2/10 | Train Loss: 0.6973 | Val Loss: 0.3649 | Val F1: 0.7931 | Val Acc: 0.8661\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 3/10 | Train Loss: 0.5686 | Val Loss: 0.3982 | Val F1: 0.7628 | Val Acc: 0.8684\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4932 | Val Loss: 0.3922 | Val F1: 0.7586 | Val Acc: 0.8681\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4307 | Val Loss: 0.2665 | Val F1: 0.8263 | Val Acc: 0.8942\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 6/10 | Train Loss: 0.4116 | Val Loss: 0.2226 | Val F1: 0.8591 | Val Acc: 0.9097\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3628 | Val Loss: 0.2535 | Val F1: 0.8472 | Val Acc: 0.9097\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3490 | Val Loss: 0.1809 | Val F1: 0.8914 | Val Acc: 0.9306\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3296 | Val Loss: 0.1862 | Val F1: 0.8831 | Val Acc: 0.9269\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3321 | Val Loss: 0.1905 | Val F1: 0.8725 | Val Acc: 0.9193\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "\n",
      "Fold 3 Summary - mobilenetv3_small_100:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9193\n",
      "- F1 Score: 0.8725\n",
      "- Precision: 0.9136\n",
      "- Recall: 0.8350\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 1.3276 | Val Loss: 0.7359 | Val F1: 0.5848 | Val Acc: 0.7999\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 2/10 | Train Loss: 0.6943 | Val Loss: 1.0352 | Val F1: 0.4415 | Val Acc: 0.7599\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 3/10 | Train Loss: 0.6097 | Val Loss: 0.2929 | Val F1: 0.8244 | Val Acc: 0.8866\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 4/10 | Train Loss: 0.5333 | Val Loss: 0.3589 | Val F1: 0.7953 | Val Acc: 0.8489\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4693 | Val Loss: 0.2732 | Val F1: 0.8341 | Val Acc: 0.9028\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3999 | Val Loss: 0.3386 | Val F1: 0.7909 | Val Acc: 0.8816\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3889 | Val Loss: 0.2150 | Val F1: 0.8632 | Val Acc: 0.9104\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3734 | Val Loss: 0.2182 | Val F1: 0.8641 | Val Acc: 0.9167\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3359 | Val Loss: 0.2114 | Val F1: 0.8612 | Val Acc: 0.9150\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3210 | Val Loss: 0.1931 | Val F1: 0.8767 | Val Acc: 0.9236\n",
      "GPU Memory: Allocated 98.0MB, Reserved 506.0MB\n",
      "\n",
      "Fold 4 Summary - mobilenetv3_small_100:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9236\n",
      "- F1 Score: 0.8767\n",
      "- Precision: 0.9404\n",
      "- Recall: 0.8210\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 1.3672 | Val Loss: 0.5646 | Val F1: 0.7055 | Val Acc: 0.8161\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 2/10 | Train Loss: 0.7023 | Val Loss: 0.4121 | Val F1: 0.7441 | Val Acc: 0.8469\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 3/10 | Train Loss: 0.5937 | Val Loss: 0.3321 | Val F1: 0.8025 | Val Acc: 0.8614\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4899 | Val Loss: 0.2921 | Val F1: 0.8320 | Val Acc: 0.8826\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4764 | Val Loss: 0.2546 | Val F1: 0.8371 | Val Acc: 0.8948\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 6/10 | Train Loss: 0.4073 | Val Loss: 0.2522 | Val F1: 0.8448 | Val Acc: 0.9015\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3615 | Val Loss: 0.2340 | Val F1: 0.8529 | Val Acc: 0.9110\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3358 | Val Loss: 0.2383 | Val F1: 0.8469 | Val Acc: 0.9097\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3462 | Val Loss: 0.1928 | Val F1: 0.8803 | Val Acc: 0.9223\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3368 | Val Loss: 0.2011 | Val F1: 0.8650 | Val Acc: 0.9140\n",
      "GPU Memory: Allocated 98.3MB, Reserved 508.0MB\n",
      "\n",
      "Fold 5 Summary - mobilenetv3_small_100:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9140\n",
      "- F1 Score: 0.8650\n",
      "- Precision: 0.8996\n",
      "- Recall: 0.8330\n",
      "Loaded best fold state (fold 3) for mobilenetv3_small_100.\n",
      "Evaluating mobilenetv3_small_100 on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9316    0.9823    0.9563      2149\n",
      "      Defect     0.9610    0.8579    0.9065      1091\n",
      "\n",
      "    accuracy                         0.9404      3240\n",
      "   macro avg     0.9463    0.9201    0.9314      3240\n",
      "weighted avg     0.9415    0.9404    0.9395      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\mobilenetv3_small_100_final_model.pth\n",
      "Test Results for mobilenetv3_small_100:\n",
      "  Accuracy: 0.9404\n",
      "  F1 Score: 0.9065\n",
      "  Precision: 0.9610\n",
      "  Recall: 0.8579\n",
      "  ROC-AUC: 0.9859739080995615\n",
      "  Inference Speed: 1374.25 images/second\n",
      "\n",
      "==================================================\n",
      "Starting process for model: efficientnet_lite0\n",
      "Initialized model: efficientnet_lite0\n",
      "  - Parameters: 3,373,570\n",
      "  - Size: 13.03 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: efficientnet_lite0\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 1.3546 | Val Loss: 0.5301 | Val F1: 0.7279 | Val Acc: 0.8188\n",
      "GPU Memory: Allocated 141.1MB, Reserved 242.0MB\n",
      "Epoch 2/10 | Train Loss: 0.5285 | Val Loss: 0.3108 | Val F1: 0.8035 | Val Acc: 0.8800\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3941 | Val Loss: 0.2316 | Val F1: 0.8544 | Val Acc: 0.9091\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3394 | Val Loss: 0.2323 | Val F1: 0.8629 | Val Acc: 0.9167\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3175 | Val Loss: 0.2088 | Val F1: 0.8732 | Val Acc: 0.9203\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2830 | Val Loss: 0.1958 | Val F1: 0.8855 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2686 | Val Loss: 0.1864 | Val F1: 0.8842 | Val Acc: 0.9276\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2751 | Val Loss: 0.1943 | Val F1: 0.8748 | Val Acc: 0.9243\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2536 | Val Loss: 0.1850 | Val F1: 0.8934 | Val Acc: 0.9335\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2497 | Val Loss: 0.1865 | Val F1: 0.8863 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 141.1MB, Reserved 1804.0MB\n",
      "\n",
      "Fold 1 Summary - efficientnet_lite0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9286\n",
      "- F1 Score: 0.8863\n",
      "- Precision: 0.9345\n",
      "- Recall: 0.8428\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 1.2513 | Val Loss: 0.5188 | Val F1: 0.7307 | Val Acc: 0.8284\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 2/10 | Train Loss: 0.5299 | Val Loss: 0.2896 | Val F1: 0.8230 | Val Acc: 0.8902\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3979 | Val Loss: 0.2549 | Val F1: 0.8192 | Val Acc: 0.8919\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3420 | Val Loss: 0.2100 | Val F1: 0.8693 | Val Acc: 0.9187\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2951 | Val Loss: 0.2151 | Val F1: 0.8598 | Val Acc: 0.9150\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2838 | Val Loss: 0.1949 | Val F1: 0.8741 | Val Acc: 0.9210\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2767 | Val Loss: 0.1806 | Val F1: 0.8846 | Val Acc: 0.9292\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2614 | Val Loss: 0.1845 | Val F1: 0.8848 | Val Acc: 0.9296\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2547 | Val Loss: 0.1623 | Val F1: 0.9004 | Val Acc: 0.9378\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2535 | Val Loss: 0.1843 | Val F1: 0.8832 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "\n",
      "Fold 2 Summary - efficientnet_lite0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9286\n",
      "- F1 Score: 0.8832\n",
      "- Precision: 0.9612\n",
      "- Recall: 0.8170\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 1.4090 | Val Loss: 0.5180 | Val F1: 0.7059 | Val Acc: 0.8168\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 2/10 | Train Loss: 0.5239 | Val Loss: 0.2914 | Val F1: 0.8091 | Val Acc: 0.8803\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3867 | Val Loss: 0.2599 | Val F1: 0.8293 | Val Acc: 0.8952\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3248 | Val Loss: 0.2247 | Val F1: 0.8591 | Val Acc: 0.9114\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3136 | Val Loss: 0.2234 | Val F1: 0.8545 | Val Acc: 0.9124\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2791 | Val Loss: 0.1953 | Val F1: 0.8800 | Val Acc: 0.9259\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2721 | Val Loss: 0.1914 | Val F1: 0.8747 | Val Acc: 0.9223\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2699 | Val Loss: 0.2045 | Val F1: 0.8742 | Val Acc: 0.9226\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2498 | Val Loss: 0.1788 | Val F1: 0.8875 | Val Acc: 0.9289\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2558 | Val Loss: 0.1736 | Val F1: 0.8924 | Val Acc: 0.9332\n",
      "GPU Memory: Allocated 154.8MB, Reserved 1814.0MB\n",
      "\n",
      "Fold 3 Summary - efficientnet_lite0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9332\n",
      "- F1 Score: 0.8924\n",
      "- Precision: 0.9544\n",
      "- Recall: 0.8380\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 1.3387 | Val Loss: 0.5189 | Val F1: 0.7230 | Val Acc: 0.8267\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 2/10 | Train Loss: 0.5736 | Val Loss: 0.3300 | Val F1: 0.7744 | Val Acc: 0.8611\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 3/10 | Train Loss: 0.4002 | Val Loss: 0.2695 | Val F1: 0.8217 | Val Acc: 0.8945\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3390 | Val Loss: 0.2402 | Val F1: 0.8410 | Val Acc: 0.9031\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3134 | Val Loss: 0.2081 | Val F1: 0.8706 | Val Acc: 0.9193\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2897 | Val Loss: 0.2045 | Val F1: 0.8707 | Val Acc: 0.9196\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2942 | Val Loss: 0.1887 | Val F1: 0.8789 | Val Acc: 0.9246\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2692 | Val Loss: 0.2062 | Val F1: 0.8773 | Val Acc: 0.9256\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2761 | Val Loss: 0.1892 | Val F1: 0.8829 | Val Acc: 0.9269\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2778 | Val Loss: 0.1953 | Val F1: 0.8782 | Val Acc: 0.9246\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Early stopping triggered.\n",
      "\n",
      "Fold 4 Summary - efficientnet_lite0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9246\n",
      "- F1 Score: 0.8782\n",
      "- Precision: 0.9427\n",
      "- Recall: 0.8220\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 1.3657 | Val Loss: 0.5332 | Val F1: 0.7107 | Val Acc: 0.8145\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 2/10 | Train Loss: 0.5314 | Val Loss: 0.3217 | Val F1: 0.7828 | Val Acc: 0.8661\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3841 | Val Loss: 0.2795 | Val F1: 0.8166 | Val Acc: 0.8889\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3367 | Val Loss: 0.2334 | Val F1: 0.8474 | Val Acc: 0.9064\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3182 | Val Loss: 0.2311 | Val F1: 0.8574 | Val Acc: 0.9064\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2904 | Val Loss: 0.2096 | Val F1: 0.8770 | Val Acc: 0.9233\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2828 | Val Loss: 0.2014 | Val F1: 0.8780 | Val Acc: 0.9243\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2598 | Val Loss: 0.1959 | Val F1: 0.8757 | Val Acc: 0.9229\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2650 | Val Loss: 0.1883 | Val F1: 0.8759 | Val Acc: 0.9223\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2602 | Val Loss: 0.1892 | Val F1: 0.8723 | Val Acc: 0.9213\n",
      "GPU Memory: Allocated 154.9MB, Reserved 1824.0MB\n",
      "\n",
      "Fold 5 Summary - efficientnet_lite0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9213\n",
      "- F1 Score: 0.8723\n",
      "- Precision: 0.9410\n",
      "- Recall: 0.8130\n",
      "Loaded best fold state (fold 2) for efficientnet_lite0.\n",
      "Evaluating efficientnet_lite0 on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9209    0.9916    0.9550      2149\n",
      "      Defect     0.9806    0.8323    0.9003      1091\n",
      "\n",
      "    accuracy                         0.9380      3240\n",
      "   macro avg     0.9507    0.9119    0.9277      3240\n",
      "weighted avg     0.9410    0.9380    0.9366      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\efficientnet_lite0_final_model.pth\n",
      "Test Results for efficientnet_lite0:\n",
      "  Accuracy: 0.9380\n",
      "  F1 Score: 0.9003\n",
      "  Precision: 0.9806\n",
      "  Recall: 0.8323\n",
      "  ROC-AUC: 0.9821842828438099\n",
      "  Inference Speed: 922.40 images/second\n",
      "\n",
      "==================================================\n",
      "Starting process for model: mobilevit_xxs\n",
      "Initialized model: mobilevit_xxs\n",
      "  - Parameters: 951,666\n",
      "  - Size: 3.65 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: mobilevit_xxs\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 0.5550 | Val Loss: 0.3896 | Val F1: 0.7915 | Val Acc: 0.8667\n",
      "GPU Memory: Allocated 119.9MB, Reserved 212.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3900 | Val Loss: 0.2874 | Val F1: 0.8408 | Val Acc: 0.8968\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3310 | Val Loss: 0.2718 | Val F1: 0.8450 | Val Acc: 0.8948\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3005 | Val Loss: 0.2323 | Val F1: 0.8679 | Val Acc: 0.9157\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2879 | Val Loss: 0.2204 | Val F1: 0.8653 | Val Acc: 0.9170\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2782 | Val Loss: 0.1936 | Val F1: 0.8917 | Val Acc: 0.9319\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2678 | Val Loss: 0.1967 | Val F1: 0.8853 | Val Acc: 0.9279\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2510 | Val Loss: 0.1933 | Val F1: 0.8840 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2599 | Val Loss: 0.1853 | Val F1: 0.8924 | Val Acc: 0.9329\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2608 | Val Loss: 0.1810 | Val F1: 0.8957 | Val Acc: 0.9339\n",
      "GPU Memory: Allocated 119.9MB, Reserved 1162.0MB\n",
      "\n",
      "Fold 1 Summary - mobilevit_xxs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9339\n",
      "- F1 Score: 0.8957\n",
      "- Precision: 0.9347\n",
      "- Recall: 0.8599\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 0.5460 | Val Loss: 0.3482 | Val F1: 0.7890 | Val Acc: 0.8737\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3664 | Val Loss: 0.2830 | Val F1: 0.8282 | Val Acc: 0.8968\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3231 | Val Loss: 0.2477 | Val F1: 0.8619 | Val Acc: 0.9077\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3138 | Val Loss: 0.2378 | Val F1: 0.8425 | Val Acc: 0.9077\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2799 | Val Loss: 0.2071 | Val F1: 0.8823 | Val Acc: 0.9266\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2757 | Val Loss: 0.1867 | Val F1: 0.8954 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2684 | Val Loss: 0.1906 | Val F1: 0.8898 | Val Acc: 0.9322\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2664 | Val Loss: 0.1878 | Val F1: 0.8871 | Val Acc: 0.9296\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2627 | Val Loss: 0.1733 | Val F1: 0.9050 | Val Acc: 0.9401\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2608 | Val Loss: 0.1882 | Val F1: 0.8876 | Val Acc: 0.9306\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "\n",
      "Fold 2 Summary - mobilevit_xxs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9306\n",
      "- F1 Score: 0.8876\n",
      "- Precision: 0.9551\n",
      "- Recall: 0.8290\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 0.5432 | Val Loss: 0.3661 | Val F1: 0.7827 | Val Acc: 0.8704\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3729 | Val Loss: 0.2743 | Val F1: 0.8400 | Val Acc: 0.8975\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3251 | Val Loss: 0.2411 | Val F1: 0.8626 | Val Acc: 0.9124\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2983 | Val Loss: 0.2209 | Val F1: 0.8685 | Val Acc: 0.9150\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2760 | Val Loss: 0.2135 | Val F1: 0.8727 | Val Acc: 0.9196\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2831 | Val Loss: 0.1860 | Val F1: 0.8977 | Val Acc: 0.9335\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2689 | Val Loss: 0.1903 | Val F1: 0.8911 | Val Acc: 0.9322\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2615 | Val Loss: 0.1897 | Val F1: 0.8836 | Val Acc: 0.9272\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2556 | Val Loss: 0.1824 | Val F1: 0.8954 | Val Acc: 0.9339\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2487 | Val Loss: 0.1821 | Val F1: 0.8884 | Val Acc: 0.9309\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "\n",
      "Fold 3 Summary - mobilevit_xxs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9309\n",
      "- F1 Score: 0.8884\n",
      "- Precision: 0.9530\n",
      "- Recall: 0.8320\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 0.5729 | Val Loss: 0.3795 | Val F1: 0.8017 | Val Acc: 0.8743\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3849 | Val Loss: 0.2920 | Val F1: 0.8105 | Val Acc: 0.8882\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3294 | Val Loss: 0.2351 | Val F1: 0.8596 | Val Acc: 0.9137\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3090 | Val Loss: 0.2157 | Val F1: 0.8650 | Val Acc: 0.9173\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2881 | Val Loss: 0.2192 | Val F1: 0.8643 | Val Acc: 0.9163\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2717 | Val Loss: 0.1921 | Val F1: 0.8834 | Val Acc: 0.9272\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2781 | Val Loss: 0.1899 | Val F1: 0.8907 | Val Acc: 0.9306\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2563 | Val Loss: 0.1923 | Val F1: 0.8883 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2559 | Val Loss: 0.1927 | Val F1: 0.8828 | Val Acc: 0.9282\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2531 | Val Loss: 0.1873 | Val F1: 0.8858 | Val Acc: 0.9266\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1166.0MB\n",
      "\n",
      "Fold 4 Summary - mobilevit_xxs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9266\n",
      "- F1 Score: 0.8858\n",
      "- Precision: 0.9121\n",
      "- Recall: 0.8610\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 0.5711 | Val Loss: 0.4058 | Val F1: 0.7485 | Val Acc: 0.8502\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3878 | Val Loss: 0.3087 | Val F1: 0.7884 | Val Acc: 0.8796\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3403 | Val Loss: 0.2646 | Val F1: 0.8371 | Val Acc: 0.8988\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 4/10 | Train Loss: 0.3213 | Val Loss: 0.2435 | Val F1: 0.8488 | Val Acc: 0.9091\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2934 | Val Loss: 0.2290 | Val F1: 0.8550 | Val Acc: 0.9107\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2842 | Val Loss: 0.2096 | Val F1: 0.8813 | Val Acc: 0.9253\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2702 | Val Loss: 0.2020 | Val F1: 0.8747 | Val Acc: 0.9206\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2602 | Val Loss: 0.1996 | Val F1: 0.8858 | Val Acc: 0.9272\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2545 | Val Loss: 0.1957 | Val F1: 0.8897 | Val Acc: 0.9296\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2549 | Val Loss: 0.1965 | Val F1: 0.8869 | Val Acc: 0.9299\n",
      "GPU Memory: Allocated 123.6MB, Reserved 1154.0MB\n",
      "\n",
      "Fold 5 Summary - mobilevit_xxs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9299\n",
      "- F1 Score: 0.8869\n",
      "- Precision: 0.9508\n",
      "- Recall: 0.8310\n",
      "Loaded best fold state (fold 2) for mobilevit_xxs.\n",
      "Evaluating mobilevit_xxs on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9270    0.9870    0.9561      2149\n",
      "      Defect     0.9706    0.8469    0.9046      1091\n",
      "\n",
      "    accuracy                         0.9398      3240\n",
      "   macro avg     0.9488    0.9170    0.9303      3240\n",
      "weighted avg     0.9417    0.9398    0.9387      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\mobilevit_xxs_final_model.pth\n",
      "Test Results for mobilevit_xxs:\n",
      "  Accuracy: 0.9398\n",
      "  F1 Score: 0.9046\n",
      "  Precision: 0.9706\n",
      "  Recall: 0.8469\n",
      "  ROC-AUC: 0.9868333447782717\n",
      "  Inference Speed: 1021.19 images/second\n",
      "\n",
      "==================================================\n",
      "Starting process for model: regnetx_002\n",
      "Initialized model: regnetx_002\n",
      "  - Parameters: 2,316,530\n",
      "  - Size: 8.92 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: regnetx_002\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 0.4524 | Val Loss: 0.2831 | Val F1: 0.8128 | Val Acc: 0.8856\n",
      "GPU Memory: Allocated 153.4MB, Reserved 224.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3325 | Val Loss: 0.2291 | Val F1: 0.8588 | Val Acc: 0.9127\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3035 | Val Loss: 0.2357 | Val F1: 0.8484 | Val Acc: 0.9071\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2971 | Val Loss: 0.1999 | Val F1: 0.8863 | Val Acc: 0.9289\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2843 | Val Loss: 0.2008 | Val F1: 0.8783 | Val Acc: 0.9246\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2645 | Val Loss: 0.1810 | Val F1: 0.8913 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2637 | Val Loss: 0.1779 | Val F1: 0.8903 | Val Acc: 0.9306\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2458 | Val Loss: 0.1700 | Val F1: 0.8977 | Val Acc: 0.9355\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2608 | Val Loss: 0.1740 | Val F1: 0.8992 | Val Acc: 0.9375\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2394 | Val Loss: 0.1672 | Val F1: 0.9030 | Val Acc: 0.9388\n",
      "GPU Memory: Allocated 153.4MB, Reserved 690.0MB\n",
      "\n",
      "Fold 1 Summary - regnetx_002:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9388\n",
      "- F1 Score: 0.9030\n",
      "- Precision: 0.9482\n",
      "- Recall: 0.8619\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 0.4687 | Val Loss: 0.2975 | Val F1: 0.7857 | Val Acc: 0.8770\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3286 | Val Loss: 0.2588 | Val F1: 0.8221 | Val Acc: 0.8958\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3004 | Val Loss: 0.2325 | Val F1: 0.8489 | Val Acc: 0.9101\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2914 | Val Loss: 0.1986 | Val F1: 0.8850 | Val Acc: 0.9269\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2709 | Val Loss: 0.1731 | Val F1: 0.9024 | Val Acc: 0.9375\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2681 | Val Loss: 0.1834 | Val F1: 0.8901 | Val Acc: 0.9312\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2495 | Val Loss: 0.1794 | Val F1: 0.8927 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2665 | Val Loss: 0.1613 | Val F1: 0.9030 | Val Acc: 0.9395\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2660 | Val Loss: 0.1696 | Val F1: 0.8913 | Val Acc: 0.9332\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2360 | Val Loss: 0.1729 | Val F1: 0.9031 | Val Acc: 0.9388\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "\n",
      "Fold 2 Summary - regnetx_002:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9388\n",
      "- F1 Score: 0.9031\n",
      "- Precision: 0.9483\n",
      "- Recall: 0.8620\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 0.4651 | Val Loss: 0.3104 | Val F1: 0.7698 | Val Acc: 0.8647\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3413 | Val Loss: 0.2522 | Val F1: 0.8280 | Val Acc: 0.8975\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 3/10 | Train Loss: 0.2984 | Val Loss: 0.2192 | Val F1: 0.8588 | Val Acc: 0.9127\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2915 | Val Loss: 0.2129 | Val F1: 0.8621 | Val Acc: 0.9160\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2813 | Val Loss: 0.1990 | Val F1: 0.8768 | Val Acc: 0.9246\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2544 | Val Loss: 0.1993 | Val F1: 0.8761 | Val Acc: 0.9226\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2559 | Val Loss: 0.2013 | Val F1: 0.8835 | Val Acc: 0.9282\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2689 | Val Loss: 0.1898 | Val F1: 0.8841 | Val Acc: 0.9289\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2480 | Val Loss: 0.1726 | Val F1: 0.9047 | Val Acc: 0.9392\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2553 | Val Loss: 0.1798 | Val F1: 0.8925 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "\n",
      "Fold 3 Summary - regnetx_002:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9315\n",
      "- F1 Score: 0.8925\n",
      "- Precision: 0.9286\n",
      "- Recall: 0.8590\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 0.4676 | Val Loss: 0.2938 | Val F1: 0.8007 | Val Acc: 0.8806\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3263 | Val Loss: 0.2419 | Val F1: 0.8493 | Val Acc: 0.9038\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 3/10 | Train Loss: 0.2973 | Val Loss: 0.2158 | Val F1: 0.8622 | Val Acc: 0.9117\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2820 | Val Loss: 0.2132 | Val F1: 0.8551 | Val Acc: 0.9137\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2737 | Val Loss: 0.2053 | Val F1: 0.8649 | Val Acc: 0.9180\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2536 | Val Loss: 0.1822 | Val F1: 0.8915 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2661 | Val Loss: 0.1849 | Val F1: 0.8837 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2570 | Val Loss: 0.1657 | Val F1: 0.8909 | Val Acc: 0.9322\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2646 | Val Loss: 0.1673 | Val F1: 0.9015 | Val Acc: 0.9378\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2507 | Val Loss: 0.1711 | Val F1: 0.9034 | Val Acc: 0.9392\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "\n",
      "Fold 4 Summary - regnetx_002:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9392\n",
      "- F1 Score: 0.9034\n",
      "- Precision: 0.9513\n",
      "- Recall: 0.8600\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 0.4594 | Val Loss: 0.2996 | Val F1: 0.8062 | Val Acc: 0.8836\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3278 | Val Loss: 0.2493 | Val F1: 0.8349 | Val Acc: 0.8981\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3126 | Val Loss: 0.2229 | Val F1: 0.8578 | Val Acc: 0.9127\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2788 | Val Loss: 0.2111 | Val F1: 0.8683 | Val Acc: 0.9173\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2777 | Val Loss: 0.2035 | Val F1: 0.8710 | Val Acc: 0.9200\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2607 | Val Loss: 0.1840 | Val F1: 0.8927 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2557 | Val Loss: 0.1825 | Val F1: 0.8860 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2704 | Val Loss: 0.1783 | Val F1: 0.8876 | Val Acc: 0.9302\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2539 | Val Loss: 0.1763 | Val F1: 0.8936 | Val Acc: 0.9329\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2517 | Val Loss: 0.1800 | Val F1: 0.8930 | Val Acc: 0.9319\n",
      "GPU Memory: Allocated 162.4MB, Reserved 698.0MB\n",
      "\n",
      "Fold 5 Summary - regnetx_002:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9319\n",
      "- F1 Score: 0.8930\n",
      "- Precision: 0.9287\n",
      "- Recall: 0.8600\n",
      "Loaded best fold state (fold 2) for regnetx_002.\n",
      "Evaluating regnetx_002 on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9328    0.9879    0.9595      2149\n",
      "      Defect     0.9730    0.8598    0.9129      1091\n",
      "\n",
      "    accuracy                         0.9448      3240\n",
      "   macro avg     0.9529    0.9238    0.9362      3240\n",
      "weighted avg     0.9463    0.9448    0.9438      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\regnetx_002_final_model.pth\n",
      "Test Results for regnetx_002:\n",
      "  Accuracy: 0.9448\n",
      "  F1 Score: 0.9129\n",
      "  Precision: 0.9730\n",
      "  Recall: 0.8598\n",
      "  ROC-AUC: 0.9885057275163474\n",
      "  Inference Speed: 1169.39 images/second\n",
      "\n",
      "==================================================\n",
      "Starting process for model: efficientnet_b0\n",
      "Initialized model: efficientnet_b0\n",
      "  - Parameters: 4,010,110\n",
      "  - Size: 15.46 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: efficientnet_b0\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 1.3328 | Val Loss: 0.6868 | Val F1: 0.7153 | Val Acc: 0.8333\n",
      "GPU Memory: Allocated 205.6MB, Reserved 328.0MB\n",
      "Epoch 2/10 | Train Loss: 0.7414 | Val Loss: 0.3597 | Val F1: 0.7977 | Val Acc: 0.8710\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 3/10 | Train Loss: 0.5406 | Val Loss: 0.3429 | Val F1: 0.8122 | Val Acc: 0.8882\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4486 | Val Loss: 0.2567 | Val F1: 0.8632 | Val Acc: 0.9144\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 5/10 | Train Loss: 0.4094 | Val Loss: 0.2149 | Val F1: 0.8711 | Val Acc: 0.9206\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3655 | Val Loss: 0.2019 | Val F1: 0.8726 | Val Acc: 0.9216\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3442 | Val Loss: 0.1877 | Val F1: 0.8970 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3388 | Val Loss: 0.1786 | Val F1: 0.8933 | Val Acc: 0.9322\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3149 | Val Loss: 0.1709 | Val F1: 0.8907 | Val Acc: 0.9306\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3329 | Val Loss: 0.1790 | Val F1: 0.8964 | Val Acc: 0.9345\n",
      "GPU Memory: Allocated 205.7MB, Reserved 2020.0MB\n",
      "\n",
      "Fold 1 Summary - efficientnet_b0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9345\n",
      "- F1 Score: 0.8964\n",
      "- Precision: 0.9387\n",
      "- Recall: 0.8579\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 1.2719 | Val Loss: 0.5191 | Val F1: 0.7633 | Val Acc: 0.8413\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 2/10 | Train Loss: 0.6809 | Val Loss: 0.3457 | Val F1: 0.8028 | Val Acc: 0.8714\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 3/10 | Train Loss: 0.5308 | Val Loss: 0.2916 | Val F1: 0.8257 | Val Acc: 0.8896\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4331 | Val Loss: 0.2162 | Val F1: 0.8766 | Val Acc: 0.9223\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3897 | Val Loss: 0.2320 | Val F1: 0.8640 | Val Acc: 0.9157\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3458 | Val Loss: 0.2060 | Val F1: 0.8765 | Val Acc: 0.9246\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3235 | Val Loss: 0.1780 | Val F1: 0.8979 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3268 | Val Loss: 0.1717 | Val F1: 0.8965 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2994 | Val Loss: 0.1555 | Val F1: 0.9101 | Val Acc: 0.9418\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2961 | Val Loss: 0.1664 | Val F1: 0.8978 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 220.6MB, Reserved 2036.0MB\n",
      "\n",
      "Fold 2 Summary - efficientnet_b0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9352\n",
      "- F1 Score: 0.8978\n",
      "- Precision: 0.9379\n",
      "- Recall: 0.8610\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 1.2901 | Val Loss: 0.5354 | Val F1: 0.7571 | Val Acc: 0.8479\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 2/10 | Train Loss: 0.6829 | Val Loss: 0.3630 | Val F1: 0.8020 | Val Acc: 0.8816\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 3/10 | Train Loss: 0.5086 | Val Loss: 0.2846 | Val F1: 0.8510 | Val Acc: 0.9077\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4365 | Val Loss: 0.2426 | Val F1: 0.8429 | Val Acc: 0.9021\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3996 | Val Loss: 0.2166 | Val F1: 0.8747 | Val Acc: 0.9210\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3537 | Val Loss: 0.1898 | Val F1: 0.8947 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3384 | Val Loss: 0.1888 | Val F1: 0.8855 | Val Acc: 0.9296\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3195 | Val Loss: 0.1706 | Val F1: 0.8994 | Val Acc: 0.9365\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3253 | Val Loss: 0.1740 | Val F1: 0.8994 | Val Acc: 0.9358\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3262 | Val Loss: 0.1790 | Val F1: 0.8954 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 220.7MB, Reserved 2038.0MB\n",
      "\n",
      "Fold 3 Summary - efficientnet_b0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9352\n",
      "- F1 Score: 0.8954\n",
      "- Precision: 0.9600\n",
      "- Recall: 0.8390\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 1.2498 | Val Loss: 0.5568 | Val F1: 0.7507 | Val Acc: 0.8456\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 2/10 | Train Loss: 0.7170 | Val Loss: 0.3630 | Val F1: 0.8072 | Val Acc: 0.8823\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 3/10 | Train Loss: 0.4929 | Val Loss: 0.2728 | Val F1: 0.8440 | Val Acc: 0.9034\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4440 | Val Loss: 0.2538 | Val F1: 0.8510 | Val Acc: 0.9041\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3881 | Val Loss: 0.1911 | Val F1: 0.8864 | Val Acc: 0.9272\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3616 | Val Loss: 0.1951 | Val F1: 0.8899 | Val Acc: 0.9292\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3408 | Val Loss: 0.1834 | Val F1: 0.8896 | Val Acc: 0.9289\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3146 | Val Loss: 0.1863 | Val F1: 0.8882 | Val Acc: 0.9292\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2804 | Val Loss: 0.1827 | Val F1: 0.8940 | Val Acc: 0.9332\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2815 | Val Loss: 0.6723 | Val F1: 0.8944 | Val Acc: 0.9329\n",
      "GPU Memory: Allocated 221.1MB, Reserved 2048.0MB\n",
      "\n",
      "Fold 4 Summary - efficientnet_b0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9329\n",
      "- F1 Score: 0.8944\n",
      "- Precision: 0.9317\n",
      "- Recall: 0.8600\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 1.2539 | Val Loss: 0.5955 | Val F1: 0.7296 | Val Acc: 0.8390\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 2/10 | Train Loss: 0.6592 | Val Loss: 0.3279 | Val F1: 0.8193 | Val Acc: 0.8826\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 3/10 | Train Loss: 0.4831 | Val Loss: 0.3069 | Val F1: 0.8324 | Val Acc: 0.8975\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 4/10 | Train Loss: 0.4239 | Val Loss: 0.2269 | Val F1: 0.8600 | Val Acc: 0.9130\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 5/10 | Train Loss: 0.3989 | Val Loss: 0.2130 | Val F1: 0.8801 | Val Acc: 0.9216\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 6/10 | Train Loss: 0.3460 | Val Loss: 0.1813 | Val F1: 0.8850 | Val Acc: 0.9282\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 7/10 | Train Loss: 0.3377 | Val Loss: 0.1988 | Val F1: 0.8835 | Val Acc: 0.9279\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 8/10 | Train Loss: 0.3128 | Val Loss: 0.1902 | Val F1: 0.8890 | Val Acc: 0.9302\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 9/10 | Train Loss: 0.3134 | Val Loss: 0.1748 | Val F1: 0.9005 | Val Acc: 0.9372\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "Epoch 10/10 | Train Loss: 0.3008 | Val Loss: 0.1550 | Val F1: 0.9107 | Val Acc: 0.9428\n",
      "GPU Memory: Allocated 220.8MB, Reserved 2028.0MB\n",
      "\n",
      "Fold 5 Summary - efficientnet_b0:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9428\n",
      "- F1 Score: 0.9107\n",
      "- Precision: 0.9413\n",
      "- Recall: 0.8820\n",
      "Loaded best fold state (fold 5) for efficientnet_b0.\n",
      "Evaluating efficientnet_b0 on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9416    0.9837    0.9622      2149\n",
      "      Defect     0.9648    0.8799    0.9204      1091\n",
      "\n",
      "    accuracy                         0.9488      3240\n",
      "   macro avg     0.9532    0.9318    0.9413      3240\n",
      "weighted avg     0.9495    0.9488    0.9481      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\efficientnet_b0_final_model.pth\n",
      "Test Results for efficientnet_b0:\n",
      "  Accuracy: 0.9488\n",
      "  F1 Score: 0.9204\n",
      "  Precision: 0.9648\n",
      "  Recall: 0.8799\n",
      "  ROC-AUC: 0.9884135993165453\n",
      "  Inference Speed: 809.82 images/second\n",
      "\n",
      "==================================================\n",
      "Starting process for model: mobilevit_xs\n",
      "Initialized model: mobilevit_xs\n",
      "  - Parameters: 1,933,618\n",
      "  - Size: 7.41 MB\n",
      "\n",
      "Starting K-Fold cross-validation for model: mobilevit_xs\n",
      "\n",
      "Starting fold 1/5\n",
      "Epoch 1/10 | Train Loss: 0.5505 | Val Loss: 0.3481 | Val F1: 0.8280 | Val Acc: 0.8942\n",
      "GPU Memory: Allocated 196.0MB, Reserved 294.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3499 | Val Loss: 0.2555 | Val F1: 0.8313 | Val Acc: 0.9018\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 3/10 | Train Loss: 0.2914 | Val Loss: 0.2130 | Val F1: 0.8830 | Val Acc: 0.9249\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2727 | Val Loss: 0.1839 | Val F1: 0.9005 | Val Acc: 0.9352\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2611 | Val Loss: 0.1896 | Val F1: 0.8907 | Val Acc: 0.9299\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2573 | Val Loss: 0.1712 | Val F1: 0.9035 | Val Acc: 0.9392\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2459 | Val Loss: 0.1620 | Val F1: 0.9099 | Val Acc: 0.9431\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2431 | Val Loss: 0.1578 | Val F1: 0.9127 | Val Acc: 0.9438\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2251 | Val Loss: 0.1518 | Val F1: 0.9163 | Val Acc: 0.9464\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2373 | Val Loss: 0.1585 | Val F1: 0.9122 | Val Acc: 0.9444\n",
      "GPU Memory: Allocated 196.0MB, Reserved 2614.0MB\n",
      "\n",
      "Fold 1 Summary - mobilevit_xs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9444\n",
      "- F1 Score: 0.9122\n",
      "- Precision: 0.9541\n",
      "- Recall: 0.8739\n",
      "\n",
      "Starting fold 2/5\n",
      "Epoch 1/10 | Train Loss: 0.5264 | Val Loss: 0.3312 | Val F1: 0.7962 | Val Acc: 0.8800\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3526 | Val Loss: 0.2500 | Val F1: 0.8532 | Val Acc: 0.9094\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3038 | Val Loss: 0.2171 | Val F1: 0.8711 | Val Acc: 0.9203\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2932 | Val Loss: 0.1936 | Val F1: 0.8819 | Val Acc: 0.9279\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2712 | Val Loss: 0.1870 | Val F1: 0.8895 | Val Acc: 0.9322\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2538 | Val Loss: 0.1759 | Val F1: 0.8881 | Val Acc: 0.9309\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2411 | Val Loss: 0.1551 | Val F1: 0.9122 | Val Acc: 0.9441\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2334 | Val Loss: 0.1573 | Val F1: 0.9114 | Val Acc: 0.9428\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2471 | Val Loss: 0.1517 | Val F1: 0.9185 | Val Acc: 0.9474\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2424 | Val Loss: 0.1536 | Val F1: 0.9154 | Val Acc: 0.9464\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "\n",
      "Fold 2 Summary - mobilevit_xs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9464\n",
      "- F1 Score: 0.9154\n",
      "- Precision: 0.9574\n",
      "- Recall: 0.8770\n",
      "\n",
      "Starting fold 3/5\n",
      "Epoch 1/10 | Train Loss: 0.5341 | Val Loss: 0.3275 | Val F1: 0.8130 | Val Acc: 0.8892\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3539 | Val Loss: 0.2542 | Val F1: 0.8512 | Val Acc: 0.9081\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3163 | Val Loss: 0.2199 | Val F1: 0.8715 | Val Acc: 0.9203\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2980 | Val Loss: 0.2020 | Val F1: 0.8849 | Val Acc: 0.9286\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2863 | Val Loss: 0.1855 | Val F1: 0.9029 | Val Acc: 0.9368\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2591 | Val Loss: 0.1869 | Val F1: 0.8940 | Val Acc: 0.9325\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2460 | Val Loss: 0.1613 | Val F1: 0.9064 | Val Acc: 0.9401\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2449 | Val Loss: 0.1609 | Val F1: 0.9182 | Val Acc: 0.9484\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2449 | Val Loss: 0.1610 | Val F1: 0.9129 | Val Acc: 0.9441\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2406 | Val Loss: 0.1588 | Val F1: 0.9035 | Val Acc: 0.9388\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2626.0MB\n",
      "\n",
      "Fold 3 Summary - mobilevit_xs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9388\n",
      "- F1 Score: 0.9035\n",
      "- Precision: 0.9444\n",
      "- Recall: 0.8660\n",
      "\n",
      "Starting fold 4/5\n",
      "Epoch 1/10 | Train Loss: 0.5298 | Val Loss: 0.3356 | Val F1: 0.8395 | Val Acc: 0.8958\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3619 | Val Loss: 0.2549 | Val F1: 0.8588 | Val Acc: 0.9101\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3214 | Val Loss: 0.2244 | Val F1: 0.8641 | Val Acc: 0.9163\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2896 | Val Loss: 0.1955 | Val F1: 0.8851 | Val Acc: 0.9269\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2603 | Val Loss: 0.1875 | Val F1: 0.8943 | Val Acc: 0.9325\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2562 | Val Loss: 0.1778 | Val F1: 0.9000 | Val Acc: 0.9372\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2529 | Val Loss: 0.1746 | Val F1: 0.8908 | Val Acc: 0.9315\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2510 | Val Loss: 0.1705 | Val F1: 0.9004 | Val Acc: 0.9382\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2365 | Val Loss: 0.1634 | Val F1: 0.9081 | Val Acc: 0.9425\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2364 | Val Loss: 0.1657 | Val F1: 0.9038 | Val Acc: 0.9392\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2622.0MB\n",
      "\n",
      "Fold 4 Summary - mobilevit_xs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9392\n",
      "- F1 Score: 0.9038\n",
      "- Precision: 0.9474\n",
      "- Recall: 0.8640\n",
      "\n",
      "Starting fold 5/5\n",
      "Epoch 1/10 | Train Loss: 0.5499 | Val Loss: 0.3705 | Val F1: 0.8053 | Val Acc: 0.8780\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 2/10 | Train Loss: 0.3708 | Val Loss: 0.3004 | Val F1: 0.8407 | Val Acc: 0.8948\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 3/10 | Train Loss: 0.3126 | Val Loss: 0.2363 | Val F1: 0.8764 | Val Acc: 0.9193\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 4/10 | Train Loss: 0.2809 | Val Loss: 0.2065 | Val F1: 0.8786 | Val Acc: 0.9256\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 5/10 | Train Loss: 0.2707 | Val Loss: 0.1958 | Val F1: 0.8888 | Val Acc: 0.9309\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 6/10 | Train Loss: 0.2452 | Val Loss: 0.1785 | Val F1: 0.9029 | Val Acc: 0.9378\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 7/10 | Train Loss: 0.2464 | Val Loss: 0.1753 | Val F1: 0.9008 | Val Acc: 0.9365\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 8/10 | Train Loss: 0.2432 | Val Loss: 0.1728 | Val F1: 0.9028 | Val Acc: 0.9378\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 9/10 | Train Loss: 0.2457 | Val Loss: 0.1777 | Val F1: 0.8943 | Val Acc: 0.9345\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "Epoch 10/10 | Train Loss: 0.2317 | Val Loss: 0.1643 | Val F1: 0.9078 | Val Acc: 0.9405\n",
      "GPU Memory: Allocated 203.5MB, Reserved 2616.0MB\n",
      "\n",
      "Fold 5 Summary - mobilevit_xs:\n",
      "Validation Metrics:\n",
      "- Accuracy: 0.9405\n",
      "- F1 Score: 0.9078\n",
      "- Precision: 0.9307\n",
      "- Recall: 0.8860\n",
      "Loaded best fold state (fold 2) for mobilevit_xs.\n",
      "Evaluating mobilevit_xs on test set...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9393    0.9865    0.9623      2149\n",
      "      Defect     0.9705    0.8744    0.9200      1091\n",
      "\n",
      "    accuracy                         0.9488      3240\n",
      "   macro avg     0.9549    0.9305    0.9411      3240\n",
      "weighted avg     0.9498    0.9488    0.9481      3240\n",
      "\n",
      "Saved final model to D:\\iate_project\\dl_output\\dl_training\\models\\mobilevit_xs_final_model.pth\n",
      "Test Results for mobilevit_xs:\n",
      "  Accuracy: 0.9488\n",
      "  F1 Score: 0.9200\n",
      "  Precision: 0.9705\n",
      "  Recall: 0.8744\n",
      "  ROC-AUC: 0.9879222489176003\n",
      "  Inference Speed: 774.33 images/second\n",
      "\n",
      "Selecting best final model...\n",
      "mobilenetv3_small_100 final score: 0.9389\n",
      "efficientnet_lite0 final score: 0.9285\n",
      "mobilevit_xxs final score: 0.9401\n",
      "regnetx_002 final score: 0.9397\n",
      "efficientnet_b0 final score: 0.9373\n",
      "mobilevit_xs final score: 0.9452\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "Best model: mobilevit_xs\n",
      "  - Size: 7.41 MB\n",
      "  - Parameters: 1,933,618\n",
      "  - Accuracy: 0.9488\n",
      "  - F1 Score: 0.9200\n",
      "  - Inference: 774.33 img/sec\n",
      "Training pipeline completed successfully!\n",
      "Cleanup done.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
